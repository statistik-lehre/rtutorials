---
title: "Mittelwertsunterschiede testen"
output:
  learnr::tutorial:
    language: de
    css: css/boxes.css
    fig_caption: no
    allow_skip: false
    progressive: false
runtime: shiny_prerendered
bibliography: ref.json
link-citations: true
description: Mittelwertunterschiede von Gruppen testen
resource_files:
- css/boxes.css
tutorial:
  id: significance
  version: 1
---

```{r setup, include=FALSE}
library(learnr)
library(rtutorials)
library(ggplot2)
library(pander)
knitr::opts_chunk$set(echo = FALSE)
```

## Inhalt

kurze Beschreibung des Inhalts

Verortung auf der Roadmap:

## Lernziele

kleine Checkliste mit abhakbaren Checkboxen:

-   <input type="checkbox" unchecked> Verstehen was ein *t*-Test ist </input>
-   <input type="checkbox" unchecked> </input>
-   <input type="checkbox" unchecked> HTML-Tag f√ºr Abs√§tze </input>
-   <input type="checkbox" unchecked> ausklappbare Abschnitte </input>
-   <input type="checkbox" unchecked> LaTex </input>


## Grundlagen

Der *t*-Test ist ein statistisches Verfahren, das verwendet wird, um zu testen, ob es einen signifikanten Unterschied zwischen den Mittelwerten zweier Gruppen gibt. Er hilft dir zu entscheiden, ob die Unterschiede zwischen diesen Mittelwerten gro√ü genug sind, um als *statistisch signifikant* zu gelten. Das bedeutet, dass sie wahrscheinlich *nicht nur durch Zufall entstanden* sind. Klingt spannend, oder? 

Stell dir also vor, du m√∂chtest wissen, ob Linksh√§nder wirklich schlauer sind
als Rechtsh√§nder. Oder ob Kaffee wirklich wach macht. Der *t*-Test hilft dir dabei zu entscheiden, ob die Unterschiede, die du siehst, wirklich signifikant sind oder einfach nur Zufall. In der Welt der Statistik hei√üt 'signifikant' also so viel wie 'wahrscheinlich nicht durch Zufall'.

Es gibt drei Haupttypen von *t*-Tests:

-   **Unabh√§ngiger *t*-Test**: Vergleicht die Mittelwerte von zwei **unabh√§ngigen Gruppen**. Perfekt, wenn du zwei verschiedene Gruppen hast (wie Linksh√§nder und Rechtsh√§nder).
-   **Abh√§ngiger oder gepaarter *t*-Test**: Vergleicht die Mittelwerte **derselben Gruppe** zu zwei verschiedenen Zeitpunkten. Ideal, wenn du dieselben Personen vor und nach einer Ver√§nderung testest (wie vor und nach dem Kaffeetrinken).
-   **Einstichproben-*t*-Test**: Testet, ob der Mittelwert **einer Gruppe** signifikant *von einem bekannten Wert* abweicht. N√ºtzlich, wenn du einen Gruppenmittelwert mit einem bekannten Mittelwert (z.B. den durchschnittlichen BMI in Deutschland) vergleichen m√∂chtest.

```{r quizz1}
quiz(caption = "Welchen *t*-Test brauchst du?",
      
  learnr::question_radio("Du m√∂chtest testen, ob sich die durchschnittlichen Blutdruckwerte von M√§nnern und Frauen unterscheiden. Welcher *t*-Test ist am geeignetsten?",
      answer("Unabh√§ngiger *t*-Test", 
             correct = TRUE),
      answer("Abh√§ngiger *t*-Test"),
      answer("Einstichproben-*t*-Test"),
      random_answer_order = TRUE,
      allow_retry = TRUE),

    learnr::question_radio("Du f√ºhrst eine Studie durch, in der du die Schlafqualit√§t von Personen vor und nach der Anwendung einer neuen Schlaftherapie vergleichst. Welcher *t*-Test sollte verwendet werden?",
      answer("Unabh√§ngiger *t*-Test"),
      answer("Abh√§ngiger *t*-Test", 
             correct = TRUE),
      answer("Einstichproben-*t*-Test"),
      random_answer_order = TRUE,
      allow_retry = TRUE),

    learnr::question_radio("Du m√∂chtest √ºberpr√ºfen, ob der durchschnittliche IQ in Ihrer Stichprobe signifikant vom nationalen Durchschnitt von 100 abweicht. Welcher *t*-Test ist hierf√ºr geeignet?",
      answer("Unabh√§ngiger *t*-Test"),
      answer("Abh√§ngiger *t*-Test"),
      answer("Einstichproben-*t*-Test", 
             correct = TRUE),
      random_answer_order = TRUE,
      allow_retry = TRUE)
)
```

Super, das hat schonmal geklappt.

## Vor dem *t*-Test

Bevor wir mit der Berechnung eines *t*-Tests anfangen, haben wir zuvor jeweils noch 2 Aufgaben zu erledigen:

1. Entscheiden, ob wir einen **gerichteten oder ungerichteten** *t*-Test rechnen wollen
2. **Voraussetzungen** f√ºr den *t*-Test (unabh√§nigiger, abh√§ngiger oder Einstichproben-*t*-Test) pr√ºfen

### 1. Gerichtete vs. Ungerichtete Hypothesen

Die Richtung des *t*-Test wird bestimmt von der Richtung unserer Hypothese. Eine Hypothese ist wie eine Vermutung - sie sagt etwas dar√ºber aus, was du in deiner Studie erwartest. In der Statistik haben wir oft zwei Hypothesen: die **Nullhypothese (H0)** und die **Alternativhypothese (H1 oder HA)**. Sagen dir diese Begriffe zun√§chst nichts, oder du m√∂chtest dein Wissen zu Hypothesen und dem Signifikanzniveau aufzufrischen l√§sst sich dieses Statistikbuch von @planing2022 empfehlen, das auch [online](https://statistikgrundlagen.de/ebook/chapter/hypothesentest-signifikanztest/) frei verf√ºgbar ist. 

- **Gerichtete Hypothese**: Hier sagst du voraus, *in welche Richtung der Unterschied geht*. Zum Beispiel: "Gruppe A wird besser abschneiden als Gruppe B."
- **Ungerichtete Hypothese**: Hierbei vermutest du nur, dass es einen Unterschied gibt, aber du *sagst nicht, in welche Richtung der Unterschied geht*. Zum Beispiel: "Es gibt einen Unterschied in den Testergebnissen zwischen Gruppe A und Gruppe B."


*Wie wirkt sich das auf den t-Test aus?*

Durch die Richtung des *t*-Test "ver√§ndert" sich das **Alphaniveau**, das wir f√ºr den Test ansetzten - aber zun√§chst die Basics: Das Alphaniveau (auch Signifikanzniveau genannt) ist ein kritischer Wert, den wir vor einem statistischen Test festlegen. Es bestimmt, wie stark die Beweise gegen unsere Nullhypothese (H0) sein m√ºssen, damit wir sie ablehnen. Das Alphaniveau ist meistens **0.05**, was bedeutet, dass wir eine 5%ige Chance akzeptieren, die Nullhypothese f√§lschlicherweise abzulehnen, wenn sie tats√§chlich wahr ist (dies wird als *Typ-1-Fehler* bzw. *Alpha-Fehler* bezeichnet).

Bei einer **gerichteten** Hypothese verwendest du einen **einseitigen** *t*-Test. Du interessierst dich **nur f√ºr eine Richtung** - entweder ob Gruppe A besser ist als Gruppe B ODER umgekehrt (das h√§ngt davon ab, wie du deine *Alternativhypothese* **H1** gerichtet hast). Dementsprechend erwartest du einen *gr√∂√üeren* oder einen *kleineren* Mittelwert. In der Grafik haben wir dir das Alpha-Niveau (*blau*) markiert  und in *rot* den *kritischen Wert* eingezeichnet. Ein gemessener (*empirischer*) *t*-Wert, der diesen kritschen Wert √ºberschreitet wird als signifikant deklariert und wir lehnen die Nullhypothese ab.

```{r gerichtet_links}
# Verteilung erstellen und einteilen
df    <- data.frame(x=seq(-3,3, by=0.005))
df$y  <- dnorm(df$x)
df$sd <- "B"
df$sd[df$x < 2.3] <- "C"
df$sd[df$x < -2.3] <- "A"


ggplot(df, aes(x, y, fill = sd)) + 
  geom_area() +   
  ylab("") + 
  xlab("t-Werte Verteilung gerichtet, H1: Mittelwert kleiner als Vergleichswert") + 
  scale_fill_manual(values=c("lightblue", "gray", "gray")) +
  geom_vline(xintercept= -2.3, col="red", linewidth=0.5, linetype = "dotted")+
  theme(legend.position = "none", axis.text.x = element_blank(),axis.ticks.x = element_blank(),axis.text.y = element_blank(),axis.ticks.y = element_blank()) 

ggplot(df, aes(x, y, fill = sd)) + 
  geom_area() +   
  ylab("") + 
  xlab("t-Werte Verteilung gerichtet, H1: Mittelwert gr√∂√üer als Vergleichswert") + 
  scale_fill_manual(values=c("gray", "lightblue","gray" )) +
  geom_vline(xintercept= 2.3, col="red", linewidth=0.5, linetype = "dotted")+
  theme(legend.position = "none", axis.text.x = element_blank(),axis.ticks.x = element_blank(),axis.text.y = element_blank(),axis.ticks.y = element_blank()) 

```
    
Was siehst du also da oben? Du kannst es dir vorstellen wie die Stichprobenkennwerteverteilung f√ºr unsere H0: der Annahme, dass es keinen Unterschied zwischen den Gruppen gibt, und der wahre Wert in Wirklichkeit 0 ist. Ein Mittelwertsunterschied (*t*-Wert) im hellblauen Bereich zu erhalten, hat eine Wahrscheinlichkeit von 5% = (alphaniveau: $p = .05$). Haben wir einen solchen Wert gefunden, gehen wir davon aus, dass wir die H0 mit einer 95% Wahrscheinlichkeit verwerfen k√∂nnen.
    
Bei einer **ungerichteten** Hypothese verwendest du einen **zweiseitigen** *t*-Test. Du schaust **in beide Richtungen** - ob Gruppe A *besser* ist als Gruppe B und ob Gruppe A *schlechter* ist als Gruppe B.

```{r ungerichtet}
# Verteilung erstellen und einteilen
df    <- data.frame(x=seq(-3,3, by=0.005))
df$y  <- dnorm(df$x)
df$sd <- "B"
df$sd[df$x < 2.6] <- "C"
df$sd[df$x < -2.6] <- "A"


ggplot(df, aes(x, y, fill = sd)) + 
  geom_area() +   
  ylab("") + 
  xlab("t-Werte Verteilung ungerichtet, H1: Mittelwert gr√∂√üer oder kleiner") + 
  scale_fill_manual(values=c("lightblue", "lightblue", "gray")) +
  geom_vline(xintercept= -2.6, col="red", linewidth=0.5, linetype = "dotted") +
  geom_vline(xintercept= 2.6, col="red", linewidth=0.5, linetype = "dotted") +
  theme(legend.position = "none", axis.text.x = element_blank(),axis.ticks.x = element_blank(),axis.text.y = element_blank(),axis.ticks.y = element_blank()) 
```

Das hat wie du siehst Auswirkungen auf das Alphaniveau (*blau*). Das Alphaniveau wird hier auf **beide Enden** der Verteilung aufgeteilt. Bei einem Alphaniveau von 5% w√ºrden wir also jeweils 2.5% auf das linke und rechte Ende der Verteilung legen, um weiterhin nur mit einer 5%-igen Wahrscheinlichkeit einen Alpha-Fehler zu begehen. Dementsprechend muss der *p-Wert* < 0.025 sein.

Wenn das jetzt zu schnell ging, kannst du wie erw√§hnt auch im Statistikbuch z.B. von @planing2022 diese Zusammenh√§nge nachlesen ([online hier](https://statistikgrundlagen.de/ebook/chapter/hypothesentest-signifikanztest/)). 

Keine Bange, das ganze ist dann bei der Berechnugn in R nur *ein Argument* in der *t*-Test-Funktion: `alternative = "two.sided"`. Das schauen wir uns dann sp√§ter nochmal an. 

## Einstichproben-*t*-Test

Mit dem Einstichproben-t-Test, wollen wir untersuchen, ob der Mittelwert unserer Stichprobe von einem bekannten Mittelwert signifikant abweicht. 

Wir stellen f√ºr unser Beispiel folgende Hypothesen auf:

- H0: Der durchschnittliche Blutzuckerspiegel unserer Studierenden weicht **nicht signifikant** vom Durchschnittswert 110 ab.
- H1: Der durchschnittliche Blutzuckerspiegel unserer Studierenden weicht **signifikant** vom Durchschnittswert 110 ab.

```{r richtungsFrage}
  learnr::question_radio("Welche Art von Hypothese haben wir hier?",
      answer("Es handelt sich um eine *gerichtete* Hypothese.",
             message = "Da wir nicht spezifizieren, in welche Richtung (gr√∂√üer oder kleiner) wir einen Effekt erwarten, ist es eine ungerichtete Hypothese."),
      answer("Es handelt sich um eine *ungerichtete* Hypothese.", 
             correct = TRUE),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      incorrect = random_encouragement("de"),
      correct = "Richtig! Da wir nicht spezifizieren, in welche Richtung (gr√∂√üer oder kleiner) wir einen Effekt erwarten, ist es eine ungerichtete Hypothese.")
```

```{r richtungsFrage2}
  learnr::question_radio("Was ist daher unser kritischer p-Wert?",
      answer("Der p-Wert muss kleiner als 0.05 sein, um als signifikant zu gelten.",
             message = "Da wir eine ungerichtete Hypothese haben, verteilt sich das Alpha-Niveau von 5% auf beide Seiten der Verteilung und der p-Wert muss entsprechenden kleiner als 0.05/2 = 0.025 sein."),
      answer("Der p-Wert muss kleiner als 0.025 sein, um als signifikant zu gelten.", 
             correct = TRUE),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      incorrect = random_encouragement("de"),
      correct = "Richtig! Da wir eine ungerichtete Hypothese haben, verteilt sich das Alpha-Niveau von 5% auf beide Seiten der Verteilung und der p-Wert muss entsprechenden kleiner als 0.05/2 = 0.025 sein.")
```

Doch bevor wir diese Hypothesen testen, sollten wir zun√§chst √ºberpr√ºfen, ob die Voraussetzungen f√ºr diesen *t*-Test erf√ºllt sind.  

### Voraussetzungen

Der Einstichproben-*t*-Test hat ein paar Voraussetzungen, die erf√ºllt sein m√ºssen, damit die Ergebnisse verl√§sslich sind. Dazu geh√∂ren:

- **Normalverteilung** der Daten: Die Daten sollten ann√§hernd normalverteilt sein.
- **Unabh√§ngigkeit der Beobachtungen**: Jede Beobachtung sollte unabh√§ngig von den anderen sein.

Ebenso kannst du einen *t*-Test nur rechnen, wenn du eine **metrisch-skalierte abh√§ngige Variable** untersuchst. Da wir einen Mittelwert errechnen, muss unsere Variable ein entsprechendes Skalenniveau (metrisch) vorweisen.

Nehmen wir an, wir haben Daten √ºber die Dauer der t√§glichen Bildschirmzeit von einer Gruppe von Personen. Zuerst laden wir die notwendigen Pakete und bereiten unsere Daten vor.

```{r bildschirm, excercise = TRUE, exercise.cap = "Daten"}
# Pakete laden
library(ggplot2)
library(dplyr)

# Beispieldaten erstellen
set.seed(123) # F√ºr reproduzierbare Ergebnisse
bildschirmzeit <- rnorm(50, mean = 3, sd = 1) # Angenommen in Stunden
daten <- data.frame(bildschirmzeit)
```

#### Normalverteilung pr√ºfen

Um **grafisch** zu pr√ºfen, ob unsere Daten normalverteilt sind, k√∂nnen wir ein Histogramm mit einer Normalverteilungskurve dar√ºber legen.

```{r grafischNV, exercise = TRUE, exercise.setup = "bildschirm", exercise.cap = "Normalverteilung grafisch pr√ºfen"}
ggplot(daten, aes(x = bildschirmzeit)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = 0.2, fill = "blue", alpha = 0.7) +
  stat_function(fun = dnorm, args = list(mean = mean(daten$bildschirmzeit), sd = sd(daten$bildschirmzeit)), color = "red") +
  labs(title = "Histogramm der Bildschirmzeit mit Normalverteilungskurve",
       x = "Bildschirmzeit (Stunden)",
       y = "Dichte")
```

Um die Normalverteilung **statistisch** zu testen, k√∂nnen wir den *Shapiro-Wilk-Test* (`shapiro.test(variable)`) aus dem in *R* bereits enthaltenden `stats`-Paket verwenden. Dieser Test pr√ºft sozusagen die H0: "Die Daten sind normalverteilt".

```{r shapiro, exercise = TRUE, exercise.setup = "bildschirm", exercise.cap = "Normalverteilung statistisch pr√ºfen"}
shapiro.test(daten$bildschirmzeit)
```
Die Ausgabe ist etwas schwer zu lesen, aber vesuch es doch trotzdem mal: 

```{r quizz3}
quiz( caption ="Interpretation des Shaprio-Wilk-Tests:",
  learnr::question_numeric("Wie gro√ü ist der p-Wert f√ºr den Shaprio-Wilk-Test f√ºr unsere Daten? (alle Nachkommastellen))",
                 answer(0.9279, 
                        correct = TRUE),
                 allow_retry = TRUE),
  
  learnr::question_radio("Was sagt uns ein signifikanter p-Wert (p < .05) beim Shapiro-Wilk-Test √ºber die Normalverteilung unserer Daten?",
      answer("Die H0: 'Die Daten sind normalverteilt' ist sehr *un*wahrscheinlich, daher sind die Daten nicht normalverteilt.", 
             correct = TRUE),
      answer("Die H0: 'Die Daten sind normalverteilt' ist sehr *wahrscheinlich* und die Daten sind daher normalverteilt.",
             message = "Ein signifikanter Wert sagt uns, dass wir die H0 mit einer 5%-igen Chance eines Alpha-Fehlers verwerfen k√∂nnen. Demnach ist eine Normalverteilung der Daten nicht wahrscheinlich."),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = "Ein signifikanter Wert sagt uns, dass wir die H0 mit einer 5%-igen Chance eines Alpha-Fehlers verwerfen k√∂nnen. Demnach ist eine Normalverteilung der Daten nicht wahrscheinlich."),
  
  learnr::question_radio("Was sagt uns der von uns beobachtete p-Wert √ºber die Normalverteilung unserer Daten?",
      answer("Die Daten sind sehr wahrscheinlich nicht normalverteilt.",
             message = "Ein nicht-signifikanter (p > .05) Wert sagt uns, dass wir die H0 beibehalten sollten."),
      answer("Die Daten sind sehr wahrscheinlich normalverteilt.", 
             correct = TRUE),
      random_answer_order = TRUE,
      allow_retry = TRUE)
)
```

Hat es geklappt? Falls du Schwierigkeiten hattest, gibt es ein h√ºbsches Paket, das dir deine Ausgabe etwas strukturierter Darstellt: die `pander()`-Funktion aus dem gleichnamigen Paket. 

::: aufgabe
Nutze die Funktion `pander()`, um dir das Ergebnis, des shapiro.test() darstellen zu lassen.
:::

```{r pander, exercise = TRUE, exercise.setup = "bildschirm", exercise.cap = "pander()"}
# Pipe das Ergebniss des Shapiro-Wilk Tests in die pander() Funktion
shapiro.test(daten$bildschirmzeit) |>
  
```

```{r pander-solution}
shapiro.test(daten$bildschirmzeit) |> 
pander()
```

So solltest du schnell erkennen, dass der statistische Testwert (W) = 0.98928 und der *p*-Wert = 0.9279 betr√§gt.

#### Unabh√§ngigkeit der Beobachtungen

Die Unabh√§ngigkeit der Beobachtungen ist meistens durch das **Design der Studie** gew√§hrleistet. Stelle sicher, dass jede Beobachtung (in unserem Fall jede Person) unabh√§ngig von den anderen ist.

Wie kann man Unabh√§ngigkeit sicherstellen?

- **Zuf√§llige Stichprobenziehung**: Eine der besten Methoden, um Unabh√§ngigkeit zu gew√§hrleisten, ist die zuf√§llige Auswahl von Teilnehmenden.

- **Keine Beeinflussung zwischen Teilnehmenden**: Achte darauf, dass die Teilnehmenden sich untereinander nicht beeinflussen k√∂nnen. Das hei√üt, die Erfahrungen oder Antworten einer Person sollten keinen Einfluss auf eine andere Person haben.

- **Kontrolle von externen Faktoren**: Versuche, externe Faktoren, die deine Teilnehmenden beeinflussen k√∂nnten, zu kontrollieren oder zu minimieren.

Und schon bist du fertig! Jetzt hast du gelernt, wie du die Voraussetzungen f√ºr einen *Einstichproben-t-Test* in *R* pr√ºfen kannst. Super gemacht! üåü Jetzt zum spannenden Teil: der Berchenung des eigentlichen *t*-Tests.


### Berechnen des Einstichproben *t*-Test

#### Schritt 1: Daten vorbereiten

Wir beginnen damit, dass wir unsere Daten vorbereiten. Nehmen wir an, wir haben eine Stichprobe von Daten, die den durchschnittlichen Blutzuckerspiegel einer Gruppe von Studierenden repr√§sentiert. Wir wollen testen, ob dieser Durchschnitt signifikant von dem bekannten Durchschnittswert (sagen wir 110 mg/dL) abweicht. 

```{r blutzucker, exercise = TRUE, exercise.cap = "Daten vorbereiten"}
# Beispieldaten
blutzucker_werte <- c(102, 98, 105, 101, 99, 100, 106, 103, 104, 97)

# Bekannter Populationsmittelwert
populationsmittelwert <- 110

```

#### Schritt 2: Einstichproben-*t*-Test durchf√ºhren

Jetzt f√ºhren wir den eigentlichen *t*-Test durch, indem wir die `t.test()`-Funktion in *R* verwenden.

Die Funktion f√ºr den Einstichproben-*t*-Test sieht folgenderma√üen aus:

```{r, echo = TRUE, eval = FALSE}
# Einstichproben-T-Test
t.test(x = data, mu = 100, alternative = "two.sided")
```

Wobei:

- `x` unsere Daten entgegennimmt 
- `mu` den bekannten Mittelwert, gegen den wir testen wollen, darstellt
- das Argument `alternative = "two.sided"` sagt, dass wir eine **ungerichtete** Hypothese testen (*default*). 

::: aufgabe
Nutze den grade gelernten Code um unsere `blutzucker_werte` gegen den Populationsmittelwert `110` zu testen und beachte, dass wir eine *ungerichtete* Hypothese testen.

Wenn du magst, lass dir das Ergebniss wieder mithilfe der pander()-Funktion darstellen.
:::

```{r Einttest, exercise = TRUE, exercise.setup = "blutzucker", exercise.cap = "Daten vorbereiten"}
t.test() 
```

```{r Einttest-solution}
t.test(x = blutzucker_werte, mu = 110, alternative = "two.sided") |> 
  pander()
```

#### Schritt 3: Ergebnisse interpretieren und berichten

Das Ergebnis des *t*-Tests gibt uns mehrere wichtige Informationen:

- ***t*-Wert**: Setzt die Entfernung des Stichprobenmittelwerts vom Populationsmittelwert in Relation zur Stichprobenvarianz.
- Freiheitsgrade (**df**): Anzahl der Werte in der Stichprobe, die frei variieren k√∂nnen (meist definiert als die `Anzahl an Beobachtungen - 1`).
- **p-Wert**: Gibt die Wahrscheinlichkeit an, unter der Nullhypothese einen solchen oder extremeren Wert zu erhalten. Ein niedriger *p-Wert* (typischerweise *p < 0.05*) deutet darauf hin, dass wir die Nullhypothese ablehnen k√∂nnen.

**Beispielinterpretation**

Hast du den *t*-Test durchgef√ºhrt und m√∂chtest die Ergebnisse in deiner Forschungsarbeit angeben w√ºrdest du es nach **APA Standard** wie folgt schreiben ([mehr zu APA](https://apastyle.apa.org/)):

"Ein Einstichproben-*t*-Test ergab einen statistisch signifikanten Unterschied zwischen dem durchschnittlichen Blutzuckerspiegel einer Stichprobe von 10 Personen ($M = 101.2, SD = 3.1$) und dem bekannten Populationsmittelwert von 100 mg/dL, $t(9) = 2.34, p = .04$. Dieses Ergebnis deutet darauf hin, dass der durchschnittliche Blutzuckerspiegel der Stichprobe signifikant h√∂her ist als der Populationsmittelwert."

<!-- Beispiel mit einkaufen rechnen lassen?! -->

Super! Als n√§chstes schauen wir uns an, wie wir f√ºr zwei unabh√§ngige Gruppen einen *t*-Test berechnen k√∂nnen.

## t-Test f√ºr unabh√§ngige Gruppen

Der unabh√§ngige *Zweistichproben-T-Test* wird verwendet, wenn du **zwei unterschiedliche Gruppen** miteinander vergleichen m√∂chtest. Zum Beispiel:

- Die Wirkung eines Medikaments im Vergleich zu einem Placebo.
- Die Leistung von Sch√ºlern in zwei verschiedenen Klassen.
- Die Kundenzufriedenheit in zwei Filialen eines Gesch√§fts.

Der Schl√ºsselpunkt ist, dass die beiden Gruppen *unabh√§ngig* voneinander sein m√ºssen, d.h., die Daten der einen Gruppe d√ºrfen die der anderen Gruppe nicht beeinflussen.

### Hypothesen aufstellen

Wir wollen diesmal herausfinden, ob Autofahrende einen h√∂heren Ruhepuls als Radfahrende haben. 
Damit w√§re unsere 

- H1: Autofahrende haben einen h√∂heren Ruhepuls als Radfahrende.

```{r quizz4}
quiz(caption = "Hypothesen erstellen:",
      
  learnr::question_radio("Jetzt haben wir bereits eine H1, aber was w√§re die zu testende H0?",
      answer("Autofahrende haben den gleichen Ruhepuls wie Radfahrende.", 
             correct = TRUE),
      answer("Radfahrende haben einen h√∂heren Ruhepuls als Autofahrende.",
             message = "Die H0 geht immer davon aus, das wir keinen signifikanten Unterschied haben."),
      answer("Autofahrende haben einen kleineren Ruhepuls als Radfahrende.",
             message = "Die H0 geht immer davon aus, das wir keinen signifikanten Unterschied haben."),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = random_praise("de"),
      incorrect= random_encouragement("de")),

    learnr::question_radio("Welche Art Hypothese haben wir hier?",
      answer("gerichtete Hypothese", 
            correct = TRUE),
      answer("ungerichtete Hypothese"),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = random_praise("de"),
      incorrect= random_encouragement("de"))
)
```

Hier ein kurzer Einblick in die Generierung unserer Beispieldaten.

```{r ruhepuls, exercise = TRUE, exercise.cap = "Daten vorbereiten" }
set.seed(123)  # F√ºr reproduzierbare Ergebnisse
puls_autofahrende <- rnorm(30, mean = 80, sd = 10)  # Mittelwert: 80, SD: 10
puls_radfahrende <- rnorm(30, mean = 72, sd = 8)   # Mittelwert: 72, SD: 8
```

### Voraussetzungen pr√ºfen

Auch hier gibt es wieder spezifische Voraussetzungen zu pr√ºfen, bevor wir diesen Test rechnen sollten:

1. **Normalverteilung der Daten in beiden Gruppen**: Die Daten in **beiden** Gruppen sollten ann√§hernd normalverteilt sein.
2. **Unabh√§ngigkeit der Gruppen**: Die Daten in einer Gruppe sollten nicht von den Daten in der anderen Gruppe beeinflusst werden.
3. **Varianzhomogenit√§t** (gleiche Varianzen): Die Varianzen in beiden Gruppen sollten √§hnlich sein.

1. Wie du die **Normalverteilung** pr√ºfst hast du ja grade bereits gelernt. Es gibt da, wie so oft, neben dem Histogram noch eine weitere grafische M√∂glichkeit deine Daten auf eine Normalverteilung zu √ºberpr√ºfen: das *Q-Q-Plot*. 

Ein **Q-Q-Plot** ist ein grafisches Werkzeug zur Pr√ºfung der Normalverteilung einer Datenserie. Es zeigt, ob die Verteilung einer Variablen mit der einer Normalverteilung √ºbereinstimmt. **Wenn die Daten normalverteilt sind, sollten die Punkte im QQ-Plot etwa entlang einer geraden Linie liegen**. Die Funktion `qqnorm(data)` tr√§gt deine Daten gegen die Daten der Normalverteilung in einen Plot auf. Um mehr √ºber die Funktion zu erfahren kannst du wie gewohnt auch `?qqnorm` in deine Console eingeben.

```{r qqplot, exercise = TRUE, exercise.setup = "ruhepuls", exercise.cap = "QQ-Plot"}
# QQ-Plot erstellen
qqnorm(puls_autofahrende)
qqline(puls_autofahrende, col = "red") # F√ºgt eine Referenzlinie hinzu
qqnorm(puls_radfahrende)
qqline(puls_radfahrende, col = "red") # F√ºgt eine Referenzlinie hinzu

```

2. **Unabh√§ngigkeit der Gruppen**. Dies ist wiedermal im vorhinein durch das Design deiner Studie zu bewerkstelligen. Sind deine Gruppen nicht unabh√§ngig, kannst du in dem Fall einen  *t*-Test f√ºr abh√§ngige Gruppen rechnen.

3. **Varianzhomogenit√§t**: klingt zun√§chst nach einem komplizierten Wort, aber *Varianz*-*Homogenit√§t* sagt lediglich, dass die **Varianzen** **homogen** (gleich) zwischen den Gruppen sein m√ºssen. 

Auch daf√ºr gibt es bereits einen statistischen Test, den wir nutzen k√∂nnen, um dies zu √ºberpr√ºfen: der `leveneTest()` aus dem Paket `car`. 

```{r levenecode, echo = TRUE, eval = FALSE}
library(car)
leveneTest(data, gruppen)
```

F√ºr unsere Zwecke geben wir der Funktion als Argumente, unsere Daten und einen Factor f√ºr die beiden Gruppen, die wir auf Varianzhomogenit√§t untersuchen wollen. 

```{r levene, exercise = TRUE, exercise.setup = "ruhepuls", exercise.cap = "levene test"}
library(car)
leveneTest(gruppe1, gruppe2)
```


### t-Test unabh√§ngige Gruppen berechnen



## t-Test f√ºr abh√§ngige Gruppen

### Voraussetzungen pr√ºfen

### t-Test abh√§ngige Gruppen berechnen

## Abschlussquiz

```{r Abschlussquizz}
quiz(caption = "Teste dein Wissen!",

learnr::question_checkbox("Was hast du √ºber die Ma√üe der zentralen Tendenz gelernt?",
         answer("Der Median ist das Zentrum einer sortierten Datenmenge und weniger anf√§llig f√ºr Ausrei√üer.", 
                 correct = TRUE,
                 message = "Richtig! Der Median ist robust gegen√ºber Ausrei√üern."),
         answer("Der Median ist der Wert, der am h√§ufigsten in einer Datenmenge vorkommt.",
                 message = "Der Modus nicht der Median repr√§sentiert den am h√§ufigsten auftretenden Wert."),
         answer("Das artihmetische Mittel ist die Summe aller Werte geteilt durch die Anzahl der Werte.",
                 correct = TRUE,
                 message = "Genau, der Mittelwert wird durch die Summe der Werte geteilt durch ihre",
                 "Anzahl errechnet."),
         allow_retry = TRUE,
         random_answer_order = TRUE
         ),

learnr::question_radio("Welches Ma√ü der zentralen Tendenz eignet sich f√ºr eine metrisch skalierte Variable mit gro√üen Ausrei√üerwerten?",
         answer("Der Modus.",
              message = "Du k√∂nntest auch den Modus f√ºr diese Variable bestimmen,",
              "aber du m√∂chtest ja die eine Zahl finden, die deine Daten mit den geringsten Abweichungen",
              "beschreibt. Daf√ºr die lediglich h√§ufigste Auspr√§gung zu verwenden w√§re also nicht zielf√ºhrend."),
         answer("Der Median.",
              correct = TRUE,
              message = "Richtig, der Median eignet sich gut daf√ºr ein Ma√ü der zentralen Tendenz zu bestimmen,",
              "dass gegen Ausrei√üer robust ist."),
         answer("Das artihmetische Mittel.",
              message = "Das arithmetische Mittel gibt uns f√ºr Variablen OHNE Ausrei√üer eine gute",
              "Zusammenfassung unserer Daten, aber bei gro√üen Ausrei√üern ist es anf√§llig f√ºr Verzerrungen."),
         allow_retry = TRUE,
         random_answer_order = TRUE
         ))
```

## Learnings

So hast du heute abgeschnitten:

```{r context="server"}
# Shiny App um die Anzahl richtig beantworteter Fragen anzuzeigen. 
# Funktioniert in jedem Tutorial

shiny::observeEvent(
  input$get_score, 
  {
    objs2 = learnr:::get_tutorial_state()
    
    # Number of correct questions
    
    n_correct <- 
      # Access the $correct sublist item in each list item
        lapply(objs2, purrr::pluck, "correct") |>
           # make it a vector containing: TRUE and FALSE and NAs
           # NA is appearing for list items which don't have
           # a $correct subitem
                unlist() |> 
           # Taking the sum of a logical Vector returns the number of TRUEs
                sum(na.rm=TRUE)
    
    # Number of total questions
    
    total_questions <- 
      # 1. Access $type in each list item and make it a vector of types
      lapply(objs2, purrr::pluck, "type") |> unlist()
    
    # 2. Count the number of "question" in that vector
    total_questions <- total_questions[total_questions == "question"] |> 
      length()
      
      
    output$score = shiny::renderText(
      paste0(n_correct, " von ", total_questions,
        " im gesamten Tutorial beantworteten Fragen waren richtig.")
)
    invisible()
  }
)
```

```{r score, echo=FALSE}
shiny::br()
shiny::actionButton("get_score", "Auswertung!")
shiny::br()
shiny::br()
shiny::textOutput("score")
shiny::br()
```

### Zusammenfassung

Hier ein kleiner Text, was gelernt wurde und vlt. auch warum das wichtig ist.

### Diese neuen Konzepte kennst du nun:

-   

    ```         
    Stichpunktartige Beschreibung
    ```

### Neue Funktionen

eine Tabelle mit den wichtigesten Codes des Tutorials \| Code \| Beschreibung \| \|----------------\|----------------------------------------\| \| `[ ]` \| Indizierung \| \| `&` \| UND-Operator f√ºr logische Indizierung \|

## Credit

<!-- vielleicht in diese Richtung? -->

Dieses Tutorial wurde (gr√∂√ütenteils) von Lukas Bruelheide sowie in Teilen von Marie Klosterkamp geschrieben.

ggf.: Bei der Erstellung (u.a. der Beispiele, Aufgaben und Zusammenfassung) wurde teilweise von ChatGPT gebrauch gemacht.

## Literaturverzeichnis

<!--  Wird automatisch generiert aus den @autorYYYY-Zitationen und der Bibliothek in ref.json. Das Literaturverzeichnis wird immer ans Ende generiert, deswegen muss das hier die letzte √úberschrift bleiben. -->
