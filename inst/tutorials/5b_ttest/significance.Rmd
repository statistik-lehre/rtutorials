---
title: "Mittelwertsunterschiede testen"
output:
  learnr::tutorial:
    language: de
    css: css/boxes.css
    fig_caption: no
    allow_skip: false
    progressive: false
runtime: shiny_prerendered
bibliography: ref.json
link-citations: true
description: Mittelwertunterschiede von Gruppen testen
resource_files:
- css/boxes.css
tutorial:
  id: significance
  version: 1
---

```{r setup, include=FALSE}
library(learnr)
library(rtutorials)
library(ggplot2)
library(pander)
library(tidyverse)
knitr::opts_chunk$set(echo = FALSE)
```

## Inhalt

kurze Beschreibung des Inhalts

Verortung auf der Roadmap:

## Lernziele

kleine Checkliste mit abhakbaren Checkboxen:

-   <input type="checkbox" unchecked> Was der *t*-Test ist und wann er angewendet wird </input>
-   <input type="checkbox" unchecked> Wie man die Voraussetzungen f√ºr den *t*-Test √ºberpr√ºft</input>
-   <input type="checkbox" unchecked> Wie man den T-Test in R durchf√ºhrt </input>
-   <input type="checkbox" unchecked> Die Bedeutung von Effektst√§rken </input>
-   <input type="checkbox" unchecked> Berichten der Ergebnisse nach APA-Richtlinien </input>


## Grundlagen

Der *t*-Test ist ein statistisches Verfahren, das verwendet wird, um zu testen, ob zwei Mittelwerte sich voneinander unterscheiden. Er hilft dir zu entscheiden, ob die Unterschiede zwischen diesen Mittelwerten gro√ü genug sind, um als *statistisch signifikant* zu gelten. Das bedeutet, dass sie wahrscheinlich *nicht nur durch Zufall entstanden* sind. Klingt spannend, oder?

Stell dir also vor, du m√∂chtest wissen, ob Linksh√§nder wirklich schlauer sind als Rechtsh√§nder. Oder ob Kaffee wirklich wach macht. Der *t*-Test hilft dir dabei zu entscheiden, ob die Unterschiede, die du siehst, wirklich signifikant sind oder ob sie als zuf√§llige Variation eingeordnet werden sollten. Dabei werden wir niemals herausfinden, wie wahrscheinlich es ist, ob es den Unterschied wirklich gibt - aber wir k√∂nnen berechnen, wie wahrscheinlich unsere Daten sind unter der Annahme, dass es in Wahrheit keinen Unterschied gibt. Sind die Daten sehr schlecht vereinbar mit dieser Annahme, dass es keinen Unterschied gibt, k√∂nnen wir davon ausgehen, dass es wirklich einen Unterschied gibt! 

Es gibt drei Haupttypen von *t*-Tests:

-   **Unabh√§ngiger oder ungepaarter *t*-Test**: Vergleicht die Mittelwerte von zwei **unabh√§ngigen Gruppen**. Perfekt, wenn du zwei verschiedene Gruppen hast (wie Linksh√§nder und Rechtsh√§nder).
-   **Abh√§ngiger oder gepaarter *t*-Test**: Vergleicht die Mittelwerte **derselben Gruppe** zu zwei verschiedenen Zeitpunkten. Ideal, wenn du dieselben Personen vor und nach einer Ver√§nderung testest (wie vor und nach dem Kaffeetrinken).
-   **Einstichproben-*t*-Test**: Testet, ob der Mittelwert **einer Gruppe** signifikant *von einem bekannten Wert* abweicht. N√ºtzlich, wenn du einen Gruppenmittelwert mit einem bekannten Mittelwert (z.B. den durchschnittlichen BMI in Deutschland) vergleichen m√∂chtest.

```{r quiz1}
quiz(caption = "Welchen *t*-Test brauchst du?",
      
  learnr::question_radio("Du m√∂chtest testen, ob sich die durchschnittlichen Blutdruckwerte von M√§nnern und Frauen unterscheiden. Welcher *t*-Test ist am geeignetsten?",
      answer("Unabh√§ngiger *t*-Test", 
             correct = TRUE),
      answer("Abh√§ngiger *t*-Test"),
      answer("Einstichproben-*t*-Test"),
      random_answer_order = TRUE,
      correct = random_praise("de"),
      incorrect = random_encouragement("de"),
      allow_retry = TRUE),

    learnr::question_radio("Du f√ºhrst eine Studie durch, in der du die Schlafqualit√§t von Personen vor und nach der Anwendung einer neuen Schlaftherapie vergleichst. Welcher *t*-Test sollte verwendet werden?",
      answer("Unabh√§ngiger *t*-Test"),
      answer("Abh√§ngiger *t*-Test", 
             correct = TRUE),
      answer("Einstichproben-*t*-Test"),
      random_answer_order = TRUE,
      correct = random_praise("de"),
      incorrect = random_encouragement("de"),
      allow_retry = TRUE),

    learnr::question_radio("Du m√∂chtest √ºberpr√ºfen, ob der durchschnittliche IQ in Ihrer Stichprobe signifikant vom nationalen Durchschnitt von 100 abweicht. Welcher *t*-Test ist hierf√ºr geeignet?",
      answer("Unabh√§ngiger *t*-Test"),
      answer("Abh√§ngiger *t*-Test"),
      answer("Einstichproben-*t*-Test", 
             correct = TRUE),
      random_answer_order = TRUE,
      correct = random_praise("de"),
      incorrect = random_encouragement("de"),
      allow_retry = TRUE)
)
```

Super, das hat schonmal geklappt.

## Vor dem *t*-Test

Bevor wir mit der Berechnung eines *t*-Tests anfangen, haben wir zuvor jeweils noch 2 Aufgaben zu erledigen:

1.  Entscheiden, ob wir einen **gerichteten oder ungerichteten** *t*-Test rechnen wollen
2.  **Voraussetzungen** f√ºr den *t*-Test (unabh√§nigiger, abh√§ngiger oder Einstichproben-*t*-Test) pr√ºfen

### 1. Gerichtete vs. Ungerichtete Hypothesen

Die Richtung des *t*-Test wird bestimmt von der Richtung unserer Hypothese. Eine Hypothese ist wie eine Vermutung - sie sagt etwas dar√ºber aus, was du in deiner Studie erwartest. In der Statistik haben wir oft zwei Hypothesen: die **Nullhypothese (H0)** und die **Alternativhypothese (H1 oder HA)**. Sagen dir diese Begriffe zun√§chst nichts, oder du m√∂chtest dein Wissen zu Hypothesen und dem Signifikanzniveau aufzufrischen l√§sst sich dieses Statistikbuch von @planing2022 empfehlen, das auch [online](https://statistikgrundlagen.de/ebook/chapter/hypothesentest-signifikanztest/) frei verf√ºgbar ist.

-   **Gerichtete Hypothese**: Hier sagst du voraus, *in welche Richtung der Unterschied geht*. Zum Beispiel: "Gruppe A wird besser abschneiden als Gruppe B."
-   **Ungerichtete Hypothese**: Hierbei vermutest du nur, dass es einen Unterschied gibt, aber du *sagst nicht, in welche Richtung der Unterschied geht*. Zum Beispiel: "Es gibt einen Unterschied in den Testergebnissen zwischen Gruppe A und Gruppe B."

*Wie wirkt sich das auf den t-Test aus?*

Durch die Richtung des *t*-Test "ver√§ndert" sich das **Alphaniveau**, das wir f√ºr den Test ansetzten - aber zun√§chst die Basics: Das Alphaniveau (auch Signifikanzniveau genannt) ist ein kritischer Wert, den wir vor einem statistischen Test festlegen. Es bestimmt, wie stark die Beweise gegen unsere Nullhypothese (H0) sein m√ºssen, damit wir sie ablehnen. Das Alphaniveau ist meistens **0.05**, was bedeutet, dass wir eine 5%ige Chance akzeptieren, die Nullhypothese f√§lschlicherweise abzulehnen, wenn sie tats√§chlich wahr ist (dies wird als *Typ-1-Fehler* bzw. *Alpha-Fehler* bezeichnet).

Bei einer **gerichteten** Hypothese verwendest du einen **einseitigen** *t*-Test. Du interessierst dich **nur f√ºr eine Richtung** - entweder ob Gruppe A besser ist als Gruppe B ODER umgekehrt (das h√§ngt davon ab, wie du deine *Alternativhypothese* **H1** gerichtet hast). Dementsprechend erwartest du einen *gr√∂√üeren* oder einen *kleineren* Mittelwert. In der Grafik haben wir dir das Alpha-Niveau (*blau*) markiert und in *rot* den *kritischen Wert* eingezeichnet. Ein gemessener (*empirischer*) *t*-Wert, der diesen kritschen *t*-Wert √ºberschreitet wird als signifikant bezeichnet und wir lehnen die Nullhypothese ab. Der *p*-Wert, hingegen zeigt uns dabei auf, wie wahrscheinlich ein solcher *t*-Wert im Falle unserer H0-W√§re.

```{r gerichtet_links}
# Verteilung erstellen und einteilen
df    <- data.frame(x=seq(-3,3, by=0.005))
df$y  <- dnorm(df$x)
df$sd <- "B"
df$sd[df$x < 1.65] <- "C"
df$sd[df$x < -1.65] <- "A"


ggplot(df, aes(x, y, fill = sd)) + 
  geom_area() +   
  ylab("") + 
  xlab("t-Werte Verteilung der H0") + 
  scale_fill_manual(values=c("lightblue", "grey90", "grey90")) +
  geom_vline(xintercept= -1.65, col="red", linewidth=0.8, linetype = "dotted")+
  theme(legend.position = "none", 
        # axis.text.x = element_blank(),
        # axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(), panel.background = element_blank())

ggplot(df, aes(x, y, fill = sd)) + 
  geom_area() +   
  ylab("") + 
  xlab("t-Werte Verteilung der H0") + 
  scale_fill_manual(values=c("grey90", "lightblue","grey90" )) +
  geom_vline(xintercept= 1.65, col="red", linewidth=0.8, linetype = "dotted")+
  theme(legend.position = "none", 
        #axis.text.x = element_blank(), 
        #axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.background = element_blank()) 

```

Was siehst du also da oben? Es ist wie eine Stichprobenkennwerteverteilung der Nullhypothese. Also die m√∂glichen Mittelwertsunterschiede, die du erhalten k√∂nntest, unter der Annahme, dass es keinen Unterschied zwischen den Gruppen gibt, sprich: der wahre Unterschied in Wirklichkeit 0 ist. Einen *t*-Wert im hellblauen Bereich zu erhalten, hat eine Wahrscheinlichkeit von 5% = (Signifikanzniveau: $\alpha = .05$). Haben wir einen solchen Wert gefunden, gehen wir davon aus, dass wir die H0 verwerfen k√∂nnen.

Bei einer **ungerichteten** Hypothese verwendest du einen **zweiseitigen** *t*-Test. Du schaust **in beide Richtungen** - ob Gruppe A *besser* ist als Gruppe B und ob Gruppe A *schlechter* ist als Gruppe B.

```{r ungerichtet}
# Verteilung neu einteilen
df$sd <- "B"
df$sd[df$x < 1.96] <- "C"
df$sd[df$x < -1.96] <- "A"

ggplot(df, aes(x, y, fill = sd)) + 
  geom_area() +   
  ylab("") + 
  xlab("t-Werte Verteilung der H0") + 
  scale_fill_manual(values=c("lightblue", "lightblue", "grey90")) +
  geom_vline(xintercept= -1.96, col="red", linewidth=0.5, linetype = "dotted") +
  geom_vline(xintercept= 1.96, col="red", linewidth=0.5, linetype = "dotted") +
  theme(legend.position = "none", 
        # axis.text.x = element_blank(),
        # axis.ticks.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.background = element_blank()) 
```

Das hat wie du siehst Auswirkungen auf das Alphaniveau (*blau*). Das Alphaniveau wird hier auf **beide Enden** der Verteilung aufgeteilt. Bei einem Alphaniveau von 5% w√ºrden wir also jeweils 2.5% auf das linke und rechte Ende der Verteilung legen, um weiterhin nur mit einer 5%-igen Wahrscheinlichkeit einen Alpha-Fehler zu begehen. Dementsprechend muss der *p-Wert* \< 0.025 sein damit wir die H0 verwerfen.

Wenn das jetzt zu schnell ging, kannst du wie erw√§hnt auch im Statistikbuch z.B. von @planing2022 diese Zusammenh√§nge nachlesen ([online hier](https://statistikgrundlagen.de/ebook/chapter/hypothesentest-signifikanztest/)).

Keine Bange, das ganze ist dann bei der Berechnugn in R nur *ein Argument* in der *t*-Test-Funktion: `alternative = "two.sided"`. Das schauen wir uns dann sp√§ter nochmal an.

## Einstichproben-*t*-Test

::: gelb
Der Einstichproben-*t*-Test testet eine **intervallskalierte** abh√§ngige Variable in Hinsicht auf einen **festgelegten** Wert.
:::

</br>

Mit dem Einstichproben*-t*-Test, wollen wir untersuchen, ob der Mittelwert einer Stichprobe von einem bekannten Mittelwert signifikant abweicht.

### Hypothesen aufstellen

Wir stellen f√ºr unser Beispiel folgende Hypothesen auf:

-   H0: Der durchschnittliche Blutzuckerspiegel von Studierenden entspricht dem Populations-Durchschnittswert von 110.
-   H1: Der durchschnittliche Blutzuckerspiegel von Studierenden weicht vom Durchschnittswert 110 ab.

```{r richtungsFrage}
  learnr::question_radio("Welche Art von Hypothese haben wir hier?",
      answer("Es handelt sich um eine *gerichtete* Hypothese.",
             message = "Da wir nicht spezifizieren, in welche Richtung (gr√∂√üer oder kleiner) wir einen Effekt erwarten, ist es eine ungerichtete Hypothese."),
      answer("Es handelt sich um eine *ungerichtete* Hypothese.", 
             correct = TRUE),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      incorrect = random_encouragement("de"),
      correct = "Richtig! Da wir nicht spezifizieren, in welche Richtung (gr√∂√üer oder kleiner) wir einen Effekt erwarten, ist es eine ungerichtete Hypothese.")
```

<!-- Ich habe im Kopf dass R den p-Wert bei zweiseitigen Tests automatisch verdoppelt, so das wir alpha nicht halbieren m√ºssen. Das w√§re wichtig herauszufinden! ~ L-->

```{r richtungsFrage2}
  learnr::question_radio("Was ist daher unser kritischer p-Wert?",
      answer("Der p-Wert muss kleiner als 0.05 sein, um als signifikant zu gelten.",
             message = "Da wir eine ungerichtete Hypothese haben, verteilt sich das Alpha-Niveau von 5% auf beide Seiten der Verteilung und der p-Wert muss entsprechenden kleiner als 0.05/2 = 0.025 sein."),
      answer("Der p-Wert muss kleiner als 0.025 sein, um als signifikant zu gelten.", 
             correct = TRUE),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      incorrect = random_encouragement("de"),
      correct = "Richtig! Da wir eine ungerichtete Hypothese haben, verteilt sich das Alpha-Niveau von 5% auf beide Seiten der Verteilung und der p-Wert muss entsprechenden kleiner als 0.05/2 = 0.025 sein.")
```

Doch bevor wir diese Hypothesen testen, sollten wir zun√§chst √ºberpr√ºfen, ob die Voraussetzungen f√ºr diesen *t*-Test erf√ºllt sind.

### Voraussetzungen

Der Einstichproben-*t*-Test hat ein paar Voraussetzungen, die erf√ºllt sein m√ºssen, damit die Ergebnisse verl√§sslich sind. Dazu geh√∂ren:

-   **Normalverteilung** der Daten: Die Daten sollten ann√§hernd normalverteilt sein.
-   **Unabh√§ngigkeit der Beobachtungen**: Jede Beobachtung sollte unabh√§ngig von den anderen sein.

Ebenso kannst du einen *t*-Test nur rechnen, wenn du eine **metrisch-skalierte abh√§ngige Variable** untersuchst. Da wir einen Mittelwert errechnen, muss unsere Variable ein entsprechendes Skalenniveau (metrisch) vorweisen.

Nehmen wir an, wir haben eine Stichprobe von Daten, die den durchschnittlichen Blutzuckerspiegel einer Gruppe von (30) Studierenden repr√§sentiert. Wir wollen testen, ob dieser Durchschnitt signifikant von dem bekannten Durchschnittswert (sagen wir 110 mg/dL) abweicht.

Daf√ºr erstellen wir hier schnell ein paar Beispieldaten:

```{r blutzucker, exercise = TRUE, exercise.cap = "Daten vorbereiten"}
# Beispieldaten
set.seed(121) # f√ºr reproduzierbare Ergebnisse
blutzucker_werte <- rnorm(30, mean = 105, sd = 1) # 30 Werte, normalverteilt um den Wert 105 mit einer Standardabweichung von 1
df  <- data.frame(blutzucker_werte)

# Bekannter Populationsmittelwert
populationsmittelwert <- 110

```

#### Normalverteilung pr√ºfen

Um **grafisch** zu pr√ºfen, ob unsere Daten normalverteilt sind, k√∂nnen wir ein Histogramm mit einer Normalverteilungskurve dar√ºber legen.

```{r grafischNV, exercise = TRUE, exercise.setup = "blutzucker", exercise.cap = "Normalverteilung grafisch pr√ºfen"}
ggplot(df, aes(x = blutzucker_werte)) +
  geom_histogram(aes(y = after_stat(density)), binwidth = 0.4, fill = "blue", alpha = 0.7) +
  stat_function(fun = dnorm, args = list(mean = mean(df$blutzucker_werte), sd = sd(df$blutzucker_werte)), color = "red") +
  labs(title = "Histogramm der Blutzuckerwerte mit Normalverteilungskurve",
       x = "Bildschirmzeit (Stunden)",
       y = "Dichte")
```

Da diese grafische Interpretation, doch sehr viel √úbung bedarf, kann ich dir die statistische Variante zu Beginn sehr empfehlen:

Um die Normalverteilung **statistisch** zu testen, k√∂nnen wir den *Shapiro-Wilk-Test* (`shapiro.test(variable)`) aus dem in *R* bereits enthaltenden `stats`-Paket verwenden. Dieser Test pr√ºft sozusagen die H0: "Die Daten sind normalverteilt".

```{r shapiroblut, exercise = TRUE, exercise.setup = "blutzucker", exercise.cap = "Normalverteilung statistisch pr√ºfen"}
shapiro.test(df$blutzucker_werte)
```

Die Ausgabe ist etwas schwer zu lesen, aber vesuch es doch trotzdem mal:

```{r quiz3}
quiz( caption ="Interpretation des Shapiro-Wilk-Tests:",
  learnr::question_numeric("Wie gro√ü ist der *p*-Wert f√ºr den Shapiro-Wilk-Test f√ºr unsere Daten? (alle Nachkommastellen))",
                 answer(0.6902, 
                        correct = TRUE),
                 allow_retry = TRUE),
  
  learnr::question_radio("Was sagt uns ein signifikanter *p*-Wert (p < .05) beim Shapiro-Wilk-Test √ºber die Normalverteilung unserer Daten?",
      answer("Die H0: 'Die Daten sind normalverteilt' ist sehr *un*wahrscheinlich, daher sind die Daten nicht normalverteilt.", 
             correct = TRUE),
      answer("Die H0: 'Die Daten sind normalverteilt' ist sehr *wahrscheinlich* und die Daten sind daher normalverteilt.",
             message = "Ein signifikanter Wert sagt uns, dass wir die H0 mit einer 5%-igen Chance eines Alpha-Fehlers verwerfen k√∂nnen. Demnach ist eine Normalverteilung der Daten nicht wahrscheinlich."),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = "Ein signifikanter *p-*Wert sagt uns, dass wir die H0 mit einer 5%-igen Chance eines Alpha-Fehlers verwerfen k√∂nnen. Demnach ist eine Normalverteilung der Daten nicht wahrscheinlich."),
  
  learnr::question_radio("Was sagt uns der von uns beobachtete *p*-Wert √ºber die Normalverteilung unserer Daten?",
      answer("Die Daten sind sehr wahrscheinlich nicht normalverteilt.",
             message = "Ein nicht-signifikanter (*p* > .05) Wert sagt uns, dass wir die H0 beibehalten sollten."),
      answer("Die Daten sind sehr wahrscheinlich normalverteilt.", 
             correct = TRUE),
      random_answer_order = TRUE,
      allow_retry = TRUE)
)
```

Hat es geklappt? Falls du Schwierigkeiten hattest, gibt es ein h√ºbsches Paket, das dir deine Ausgabe etwas strukturierter Darstellt: die `pander()`-Funktion aus dem gleichnamigen Paket.

::: aufgabe
Nutze die Funktion `pander()`, um dir das Ergebnis, des shapiro.test() darstellen zu lassen.
:::

```{r pander, exercise = TRUE, exercise.setup = "blutzucker", exercise.cap = "pander()"}
# Pipe das Ergebniss des Shapiro-Wilk Tests in die pander() Funktion
shapiro.test(df$blutzucker) |>
  
```

```{r pander-solution}
shapiro.test(df$blutzucker) |> 
pander()
```

So solltest du schnell erkennen, dass der statistische Testwert (W) = 0.9753 und der *p*-Wert = 0.6902 betr√§gt.

#### Unabh√§ngigkeit der Beobachtungen

Die Unabh√§ngigkeit der Beobachtungen ist meistens durch das **Design der Studie** gew√§hrleistet. Stelle sicher, dass jede Beobachtung (in unserem Fall jede Person) unabh√§ngig von den anderen ist.

Wie kann man Unabh√§ngigkeit sicherstellen?

-   **Zuf√§llige Stichprobenziehung**: Eine der besten Methoden, um Unabh√§ngigkeit zu gew√§hrleisten, ist die zuf√§llige Auswahl von Teilnehmenden.

-   **Keine Beeinflussung zwischen Teilnehmenden**: Achte darauf, dass die Teilnehmenden sich untereinander nicht beeinflussen k√∂nnen. Das hei√üt, die Erfahrungen oder Antworten einer Person sollten keinen Einfluss auf eine andere Person haben.

-   **Kontrolle von externen Faktoren**: Versuche, externe Faktoren, die deine Teilnehmenden beeinflussen k√∂nnten, zu kontrollieren oder zu minimieren.

Und schon bist du fertig! Jetzt hast du gelernt, wie du die Voraussetzungen f√ºr einen *Einstichproben-t-Test* in *R* pr√ºfen kannst. Super gemacht! üåü Jetzt zum spannenden Teil: der Berchenung des eigentlichen *t*-Tests.

### Berechnen des Einstichproben *t*-Test

Jetzt f√ºhren wir den eigentlichen *t*-Test durch, indem wir die `t.test()`-Funktion in *R* verwenden.

Die Funktion f√ºr den Einstichproben-*t*-Test sieht folgenderma√üen aus:

```{r, echo = TRUE, eval = FALSE}
# Einstichproben-T-Test
t.test(x = data, mu = 100, alternative = "two.sided")
```

Wobei:

-   `x` unsere Daten entgegennimmt
-   `mu` den bekannten Mittelwert, gegen den wir testen wollen, darstellt
-   das Argument `alternative = "two.sided"` sagt, dass wir eine **ungerichtete** Hypothese testen (*default*).

::: aufgabe
Nutze den grade gelernten Code um unsere `blutzucker_werte` gegen den Populationsmittelwert `110` zu testen und beachte, dass wir eine *ungerichtete* Hypothese testen.
:::

```{r Einttest, exercise = TRUE, exercise.setup = "blutzucker", exercise.cap = "Daten vorbereiten"}
t.test() 
```

```{r Einttest-solution}
t.test(x = blutzucker_werte, mu = 110, alternative = "two.sided")
```

Gehen wir die Ausgabe Zeile f√ºr Zeile durch:

``` r
One Sample t-test
```

Sagt uns, *R* hat einen Einstichprobentest, gerechnet. Super! So wollten wir es.

``` r
data:  blutzucker_werte
```

Die getesteten Daten sind: blutzucker_werte

``` r
t = -32.72, df = 29, p-value < 2.2e-16
```

Hier bekommen wir unsere gew√ºnschten statistischen Gr√∂√üen: den *t*-Wert = -32.72, die Freiheitsgrade(df) = 29 und unseren *p*-Wert (in der **wissenschafltlichen Notation**). Die wissenschaftliche Notation sagt uns, dass der *p*-Wert `2.2` noch 16 Nullen vor dem Komma f√ºhrt (`-16`) also ist der *p*-Wert 0.000000000000000022. (Eine 9.546**e+11** w√ºrde wiederum bedeuten, dass elf Nullen vor dem Komma stehen: 2.200.000.000.000).

``` r
alternative hypothesis: true mean is not equal to 110
```

Hier gibt uns *R* sogar die H1: "der Mittelwert ist nicht gleich 110." mit aus.

``` r
95 percent confidence interval:
 104.7114 105.3336
```

Zus√§tzlich erh√§lst du die obere und untere Grenze des 95% Intervalls. Hier bedeutet es, dass der wahre Mittelwert unserer Stichprobe mit 95%iger Wahrscheinlichkeit in dem Intervall von 104.7114 und 105.3336 liegt.

``` r
sample estimates:
mean of x 
   105.0225 
```

Zu guter letzt erhalten wir noch den Mittelwert unserer Stichprobe (105.02). Um dazu auch die Standardabweichung zu erhalten kannst du deine Variable in die Funktion `sd()` eingeben. (Das ist Teil der deskriptiven Analyse deiner Daten)

```{r sd, exercise = T, exercise.setup = "blutzucker", exercise.cap = "SD berechnen" }
sd(blutzucker_werte)
```

Jetzt wei√üt du wo du deine Werte findest und wir k√∂nnen zur Interpretation und dem Berichten weiter gehen.

#### Ergebnisse interpretieren und berichten

Das Ergebnis des *t*-Tests gibt uns mehrere wichtige Informationen:

-   ***t*****-Wert**: Setzt die Entfernung des Stichprobenmittelwerts vom Populationsmittelwert in Relation zur Stichprobenvarianz. (Achte hier auch auf das Vorzeichen: `-` = der Mittelwert ist **niedriger** als der Populationswert, `+` der Wert ist **h√∂her**.)
-   Freiheitsgrade (**df**): Anzahl der Werte in der Stichprobe, die frei variieren k√∂nnen (meist definiert als die `Anzahl an Beobachtungen - 1`).
-   **p-Wert**: Gibt die Wahrscheinlichkeit an, unter der Nullhypothese einen solchen oder extremeren Wert zu erhalten. Ein niedriger *p-Wert* (typischerweise *p \< 0.05*, f√ºr unsere ungerichtete Hypothese *0.025*) deutet darauf hin, dass wir die Nullhypothese verwerfen k√∂nnen.

Damit ist der *p*-Wert kleiner als unser zweiseitiges Alphaniveau von 0.025 und kann daher als signifikant gewertet werden.

**Beispielinterpretation**

Hast du den *t*-Test durchgef√ºhrt und m√∂chtest die Ergebnisse in deiner Forschungsarbeit angeben w√ºrdest du es nach **APA Standard** wie folgt schreiben ([mehr zu APA](https://apastyle.apa.org/) oder hier eine gute [Zusammenmfassung der Universit√§t Stuttgart wie statistische Kenngr√∂√üen nach APA 7 berichtet werden](https://www.inspo.uni-stuttgart.de/institut/aii/dokumente/APA-Manuskriptgestaltung-Angabe-statistischer-Werte-Zitieren-Literatur.pdf)):

F√ºr den Bericht eines *p*-Werts werden zuerst die Kennwerte der Stichprobe (*M* = "Mittelwert", *SD* = "Standardabweichung") angegeben. Dann die statistischen Gr√∂√üen nach diesem Schema: `t("df") = "t-Wert", p "Signifikanzniveau"`. Dabei werden die statistischen Kennwerte, wie z.B. *t* und *p* kursiv geschrieben. Die Werte in "" erstetzt du durch die entsprechenden Werte der Ausgabe. Das Signifikanzniveau, das dein *p*-Wert √ºberschreiten kann, ist dabei in 3 Level aufgeteilt:

-   p \< .05\* signifikant
-   p \< .01\*\* hoch signifikant
-   p \< .001\*\*\* h√∂chst signifikant

Das kann dann z.B so aussehen:

::: blau-nb
"Ein Einstichproben-*t*-Test ergab einen statistisch signifikanten Unterschied zwischen dem durchschnittlichen Blutzuckerspiegel einer Stichprobe von 10 Studierenden ($M = 105, SD = 0.83$) und dem bekannten Populationsmittelwert von 110 mg/dL, $t(29) = -32.72, p < .001$. Dieses Ergebnis deutet darauf hin, dass der durchschnittliche Blutzuckerspiegel der Stichprobe signifikant niedriger ist als der Populationsmittelwert."
:::

</br>

<!-- (Sidenote: auch wenn unser *p*-Wert sehr klein ist, bitte niemals $p = 0.000$ schreiben, besser $p < .001$, da es sich um Wahrscheinlichkeiten handelt und eine 0%-Wahrscheinlichkeit logisch aufgrund von Zufallseffekten nicht m√∂glich ist - anders herum gesagt, es ist immer, wenn auch nicht sehr wahrscheinlich, m√∂glich einen solchen Wert zuf√§llig f√ºr unsere Verteilung zu erhalten, wenn die H0 wahr ist.)  -->

<!-- Beispiel mit einkaufen rechnen lassen?! -->

Super! Als n√§chstes schauen wir uns an, wie wir f√ºr zwei unabh√§ngige Gruppen einen *t*-Test berechnen k√∂nnen.

## t-Test f√ºr unabh√§ngige Gruppen

::: gelb
Der unabh√§ngige *t*-Test testet eine unabh√§ngige Variable mit **2 Auspr√§gungen** (Kategorien/ Gruppen) in Hinsicht auf eine **intervallskalierte** abh√§ngige Variable.
:::

</br>

Der unabh√§ngige *Zweistichproben-T-Test* wird verwendet, wenn du **zwei unterschiedliche Gruppen** miteinander vergleichen m√∂chtest. Zum Beispiel:

-   Die Wirkung eines Medikaments im Vergleich zu einem Placebo.
-   Die Leistung von Sch√ºlern in zwei verschiedenen Klassen.
-   Die Kundenzufriedenheit in zwei Filialen eines Gesch√§fts.

Der Schl√ºsselpunkt ist, dass die beiden Gruppen *unabh√§ngig* voneinander sein m√ºssen, d.h., die Daten der einen Gruppe d√ºrfen die der anderen Gruppe nicht beeinflussen.

### Hypothesen aufstellen

Wir wollen diesmal herausfinden, ob Autofahrende einen h√∂heren Ruhepuls als Radfahrende haben. Damit w√§re unsere

-   H1: Autofahrende haben einen h√∂heren Ruhepuls als Radfahrende.

```{r quiz4}
quiz(caption = "Hypothesen erstellen:",
      
  learnr::question_radio("Jetzt haben wir bereits eine H1, aber was w√§re die zu testende H0?",
      answer("Autofahrende haben den gleichen Ruhepuls wie Radfahrende.", 
             correct = TRUE),
      answer("Radfahrende haben einen h√∂heren Ruhepuls als Autofahrende.",
             message = "Die H0 geht immer davon aus, das wir keinen signifikanten Unterschied haben."),
      answer("Autofahrende haben einen kleineren Ruhepuls als Radfahrende.",
             message = "Die H0 geht immer davon aus, das wir keinen signifikanten Unterschied haben."),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = random_praise("de"),
      incorrect= random_encouragement("de")),

    learnr::question_radio("Welche Art Hypothese haben wir hier?",
      answer("gerichtete Hypothese", 
            correct = TRUE),
      answer("ungerichtete Hypothese"),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = random_praise("de"),
      incorrect= random_encouragement("de"))
)
```

Hier ein kurzer Einblick in die Generierung unserer Beispieldaten.

```{r ruhepuls, exercise = TRUE, exercise.cap = "Daten vorbereiten" }
set.seed(123)  # F√ºr reproduzierbare Ergebnisse
puls_autofahrende <- rnorm(30, mean = 80, sd = 10)  # Mittelwert: 80, SD: 10
puls_radfahrende <- rnorm(30, mean = 72, sd = 8)   # Mittelwert: 72, SD: 8
```

### Voraussetzungen pr√ºfen

Auch hier gibt es wieder spezifische Voraussetzungen zu pr√ºfen, bevor wir diesen Test rechnen sollten:

1.  **Normalverteilung der Daten in beiden Gruppen**: Die Daten in **beiden** Gruppen sollten ann√§hernd normalverteilt sein.

2.  **Unabh√§ngigkeit der Gruppen**: Die Daten in einer Gruppe sollten nicht von den Daten in der anderen Gruppe beeinflusst werden.

3.  **Varianzhomogenit√§t** (gleiche Varianzen): Die Varianzen in beiden Gruppen sollten √§hnlich sein.

Wie du die **Normalverteilung** pr√ºfst hast du ja grade bereits gelernt. Es gibt da, wie so oft, neben dem Histogram noch eine weitere grafische M√∂glichkeit deine Daten auf eine Normalverteilung zu √ºberpr√ºfen: das *Q-Q-Plot*.

Ein **Q-Q-Plot** ist ein grafisches Werkzeug zur Pr√ºfung der Normalverteilung einer Datenserie. Es zeigt, ob die Verteilung einer Variablen mit der einer Normalverteilung √ºbereinstimmt. **Wenn die Daten normalverteilt sind, sollten die Punkte im QQ-Plot etwa entlang einer geraden Linie liegen**. Die Funktion `qqnorm(data)` tr√§gt deine Daten gegen die Daten der Normalverteilung in einen Plot auf. Um mehr √ºber die Funktion zu erfahren kannst du wie gewohnt auch `?qqnorm` in deine Console eingeben.

```{r qqplot, exercise = TRUE, exercise.setup = "ruhepuls", exercise.cap = "QQ-Plot"}
# QQ-Plot erstellen
qqnorm(puls_autofahrende)
qqline(puls_autofahrende, col = "red") # F√ºgt eine Referenzlinie hinzu
qqnorm(puls_radfahrende)
qqline(puls_radfahrende, col = "red") # F√ºgt eine Referenzlinie hinzu
shapiro.test(puls_autofahrende)
shapiro.test(puls_radfahrende)
```

Die Plots zeigen dabei nur leichte Abweichungen an den Enden der Diagonalen und auch die Shapiro-Wilk-Tests sagen uns, dass die Daten normalverteilt sind ($p > .05$).

Weiter zur **Unabh√§ngigkeit der Gruppen**. Dies ist wiedermal im vorhinein durch das Design deiner Studie zu bewerkstelligen. Sind deine Gruppen nicht unabh√§ngig, kannst du in dem Fall einen *t*-Test f√ºr abh√§ngige Gruppen rechnen.

Zuletzt die **Varianzhomogenit√§t**: klingt zun√§chst nach einem komplizierten Wort, aber *Varianz*-*Homogenit√§t* sagt lediglich, dass die **Varianzen** **homogen** (gleich) zwischen den Gruppen sein m√ºssen.

Auch daf√ºr gibt es bereits einen statistischen Test, den wir nutzen k√∂nnen, um dies zu √ºberpr√ºfen: der `leveneTest()` aus dem Paket `car`.

``` r
library(car)
leveneTest(Modell, daten)
```

Die Funktion m√∂chte von uns jedoch, dass die Daten in einer Spalte und die Gruppen in einer zweite Spalte aufbereitet sind. Aber mit den neuen data wrangling Tricks, ist das f√ºr uns kein Problem:

```{r wrangling, exercise = TRUE, exercise.setup = "ruhepuls"}
df <- data.frame(
  puls = c(puls_autofahrende, puls_radfahrende), #Daten als 1 Vektor
  gruppe = factor(c(rep("Autofahrende", length.out = length(puls_autofahrende)), rep("Radfahrende", length.out = length(puls_autofahrende)))) #repeat "" f√ºr die L√§nge von x
)
df
```

F√ºr unsere Zwecke k√∂nnen wir so der Funktion unsere Ruhepuls-Daten als einen Vektor geben und einen Factor f√ºr die beiden Gruppen, die wir auf Varianzhomogenit√§t untersuchen wollen.

```{r levene, exercise = TRUE, exercise.setup = "wrangling", exercise.cap = "levene test"}
library(car)
leveneTest(daten ~ factor, df)
```

```{r levene-solution}
library(car)
leveneTest(puls ~ gruppe, df)
```

Als Output bekommst du folgenden Code:

``` r
Levene's Test for Homogeneity of Variance (center = median)
      Df F value  Pr(>F)  
group  1  4.7241 0.03384 *
      58                  
---
Signif. codes:  0 ‚Äò***‚Äô 0.001 ‚Äò**‚Äô 0.01 ‚Äò*‚Äô 0.05 ‚Äò.‚Äô 0.1 ‚Äò ‚Äô 1
```

-   Ein signifikantes Ergebnis (*p* \< 0.05) im Levene-Test deutet darauf hin, dass die Varianzen zwischen den Gruppen signifikant unterschiedlich sind.
-   Ein nicht signifikantes Ergebnis bedeutet, dass die Annahme der Varianzhomogenit√§t erf√ºllt ist.

```{r levenequiz}
     
  learnr::question_radio("Was sagt das Ergebnis des Levene Tests √ºber unsere Varianzhomogenit√§t aus",
      answer("Die Varianzen der Gruppen sind nicht gleich.", 
             correct = TRUE),
      answer("Die Varianzen der Gruppen sind gleich.",
             message = "Die H0 geht immer davon aus, das wir keinen signifikanten Unterschied haben, also kein Unterschied in den Varianzen vorliegt. Anhand unseres *p*-Wertes (0.034) k√∂nnen wir die H0 jedoch verwerfen."),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = "Die H0 geht immer davon aus, das wir keinen signifikanten Unterschied haben, also kein Unterschied in den Varianzen vorliegt. Anhand unseres *p*-Wertes (0.034) k√∂nnen wir die H0 jedoch verwerfen.",
      incorrect= random_encouragement("de"))
```

Praktischerweise gibt es in der `t.test()`-Funktion das Argument `var.equal = FALSE` (default), welches sogar der Standardwert ist. Die Funktion ist so schlau, dass sie, wenn wir dieses Argument nicht h√§ndisch umcodieren, selbst pr√ºft, ob Varianzhomogenit√§t gegeben ist und bei Verletzung dieser Voraussetzung statt des t-Tests einen Welch t-Test rechnet, der diese Varianzungleichheit in die Berechnung einbezieht. Daher k√∂nnen wir zur Berechnung fortschreiten.

### Berechnen des unabh√§ngigen t-Tests

Es ist soweit, wir k√∂nnen jetzt den t-Test f√ºr unabh√§ngige Gruppen rechnen, und feststellen, ob unsere Autofahrenden einen h√∂heren Ruhepuls als die Radfahrenden haben. Daf√ºr testen wir wie gewohnt die *H0: Es gibt keinen Unterschied zwischen dem Ruhepuls von Autofahrenden und Radfahrenden*.

Der `t.test()` f√ºr unabh√§ngige Gruppen hat die gleichen Argumente wie zuvor, nur das wir nun anstelle des `mu` gegen eine zweite Variable testen.

```{r twosample, exercise = TRUE, exercise.setup = "ruhepuls", exercise.cap = "unabh√§ngiger t-Test"}
t.test(puls_autofahrende, puls_radfahrende)
```

```{r twosamplequiz}
  learnr::question_radio("Was m√ºssen wir f√ºr das Argument `alternative` bei diesem *t*-Test aufgrund unserer H1 eingeben?",
      answer("greater", 
             correct = TRUE),
      answer("less",
             message = "Unsere H1 sagt, die Mittelwerte der Autofahrenden sind GR√ñ√üER als die von den Radfahrenden."),
      answer("two-sided",
             message = "Unsere H1 sagt, die Mittelwerte der Autofahrenden sind GR√ñ√üER als die von den Radfahrenden."),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = "Genau! Unsere H1 sagt, die Mittelwerte der Autofahrenden sind GR√ñ√üER als die von den Radfahrenden.",
      incorrect= random_encouragement("de"))
```

::: aufgabe
Rechne den *t*-Test f√ºr unsere Variablen `puls_autofahrende` und `puls_radfahrende` und w√§hle das ben√∂tigte Argument f√ºr `alternative` (`two.sided` / `less`/ `greater`).

Errechne au√üerdem die Standardabweichung (sd) f√ºr beide Variablen.

\*Anmerkung: Die Variablen wurden nicht in einem Data Frame gespeichert.
:::

```{r twosample2, exercise = TRUE, exercise.setup = "ruhepuls", exercise.cap = "unabh√§ngiger t-Test"}
# √§ndere x und y und f√ºge der alternative ein Argument hinzu
t.test(x, y, alternative = "")
# errechne den sd f√ºr beide Variablen
```

```{r twosample2-solution}
# wir erwarten, dass der Mittelwert gr√∂√üer ist, daher greater 
t.test(puls_autofahrende, 
       puls_radfahrende, 
       alternative = "greater")
sd(puls_autofahrende)
sd(puls_radfahrende)
```

```{r twosamplequiz2}

quiz(caption = "Analyse √ºben:",
  learnr::question_numeric("Wie gro√ü ist der *p*-Wert f√ºr den beobachteten *t*-Wert unserer H0? (auf 3 Nachkommastellen gerundet))",
                 answer(0.003, 
                        correct = TRUE),
                 allow_retry = TRUE),

learnr::question_radio("Was sagt der t-Wert 2.81 √ºber unsere Mittelwerte?",
      answer("Die Autofahrenden haben im Mittel einen 2.81 h√∂herern Ruhepuls als die Radfahrenden", 
             correct = TRUE),
      answer("Die Radfahrenden haben im Mittel einen 2.81 h√∂herern Ruhepuls als die Autofahrenden.",
             message = "Unsere H1 testet, ob der Puls von Autofahrenden h√∂her ist. Deshalb geben wir auch der t-Test Funktion zuerst die Autofahrenden (x) und dann den Vergleichswert (y) der Radfahrenden."),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = "Genau! Unsere H1 testet, ob der Puls von Autofahrenden h√∂her ist. Deshalb geben wir auch der `t.test()`-Funktion zuerst die Autofahrenden (x) und dann den Vergleichswert (y) der Radfahrenden.",
      incorrect= random_encouragement("de"))
)
```

#### Ergebnisse interpretieren und berichten

::: blau-nb
"Der unabh√§ngige-*t*-Test ergab einen statistisch signifikanten Unterschied zwischen dem Ruhepuls von Autofahrenden ($M = 79.53, SD = 9.81$) und dem Ruhepuls von Radfahrenden($M = 73.42, SD = 6.68$), $t(51.14) = 2.82, p < .001$. Dieses Ergebnis deutet darauf hin, dass Autofahrende im durchschnittlich einen h√∂heren Ruhepuls als Radfahrende besitzten."
:::

## t-Test f√ºr abh√§ngige Gruppen

::: gelb
Der abh√§ngige *t*-Test testet eine **intervallskalierte** abh√§ngige Variable in hinsicht auf eine unabh√§ngige Variable mit **2 Auspr√§gungen** (Kategorien/ Gruppen).
:::

</br>

Der *abh√§ngige* bzw. *gepaarte* *t*-Test ist ein statistisches Verfahren, das verwendet wird, um zu pr√ºfen, ob sich die Mittelwerte zweier verbundener Stichproben signifikant voneinander unterscheiden. Dieser Test ist besonders n√ºtzlich, wenn du dieselben Personen, Objekte oder F√§lle unter zwei verschiedenen Bedingungen (zum Beispiel *vor* und *nach* einer Intervention) untersuchen m√∂chtest.

*Wann wird der abh√§ngige T-Test verwendet?*

-   **Vorher-Nachher-Vergleiche**: Zum Beispiel, um die Wirkung eines Trainingsprogramms auf die Fitness zu beurteilen, indem du die Fitnesswerte vor und nach dem Programm vergleichst.
-   **Gepaarte Beobachtungen**: Wie etwa der Vergleich der Reaktionen von Paaren in einer Studie.
-   **Wiederholte Messungen**: Zum Beispiel, um den Effekt eines Medikaments zu verschiedenen Zeitpunkten zu messen.

### Hypothesen aufstellen

Wir wollen untersuchen, ob durch den Umbau einer Stra√üe in eine Fahrradstra√üe, die Anzahl an Radfahrenden zugenommen hat. Daf√ºr messen wir vor und nach dem Umbau die Anzahl an Radfahrenden pro Stunde (tageszeit).

Aufgrund von vorhergehenden Forschungsergebnissen gehen wir f√ºr unsere H1 davon aus, dass die Anzahl der Radfahrenden sich durch den Umbau erh√∂ht.

```{r gepaarthypotesenquiz}
learnr::question_radio("Was w√§re unsere H0?",
      answer("Die Anzahl an Radfahrenden hat sich durch den Umbau nicht ver√§ndert", 
             correct = TRUE),
      answer("Die Anzahl der Radfahrenden ist nach dem Umbau h√∂her als vor dem Umbau.",
             message = "Die H0 geht davon aus, dass es keinen Unterschied zwischen den Mittelwerten vor und nach dem Umbau gibt."),
      answer("Die Anzahl der Radfahrenden ist nach dem Umbau geringer als vor dem Umbau.",
             message = "Die H0 geht davon aus, dass es keinen Unterschied zwischen den Mittelwerten vor und nach dem Umbau gibt."),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = "Genau! Die H0 geht davon aus, dass es keinen Unterschied zwischen den Mittelwerten vor und nach dem Umbau gibt.",
      incorrect= random_encouragement("de"))

```

Hier ein kurzer Einblick in die Generierung unserer Beispieldaten.

```{r fahrradstrasse, exercise = TRUE, exercise.cap = "Daten vorbereiten" }
set.seed(121)  # F√ºr reproduzierbare Ergebnisse
anzahl_vorher <- rnorm(45, mean = 45, sd = 10)  # Mittelwert: 45, SD: 10
anzahl_nachher <- rnorm(45, mean = 46, sd = 8)   # Mittelwert: 46, SD: 8
tageszeit <- rep(c(0:24), 
                 length.out = length(anzahl_vorher))

df <- data.frame(anzahl_vorher,
                  anzahl_nachher, 
                  tageszeit)
```

### Voraussetzungen pr√ºfen

Der abh√§ngige *t*-Test hat einige Voraussetzungen:

1.  **Abh√§ngige Stichproben**: Die beiden Stichproben m√ºssen gepaart sein, d.h., es muss eine logische Verbindung zwischen den Beobachtungen in jeder Gruppe geben.

2.  **Normalverteilung der Differenzen**: Die Differenzen zwischen den gepaarten Daten sollten ann√§hernd normalverteilt sein.

3.  Wie gewohnt, wird die Abh√§ngigkeit der Stichproben durch unser Versuchsdesign umgesetzt. Die gleichen Probanden werden zu zwei Zeitpunkten befragt, oder die Temperatur am selben Ort zu einer unterschiedlichen Uhrzeit erfasst.

4.  Wir m√ºssen diesmal nicht sicherstellen, dass die Variablen an sich normalverteilt sind, sondern die Unterschiede von `x1` zu `x2`, und `y1` zu `y2` usw. normalverteilt sind. F√ºr Stichproben \> 30, kannst du von einer Normalverteilung ausgehen. Wir k√∂nnen es hier aber nochmal testen.

Schauen wir uns also die Verteilung der Differenzen an. Daf√ºr m√ºssen wir zun√§chst nat√ºrlich erst die Differenzen berechnen.

::: aufgabe
Nutze die 'mutate()'-Funktion, um die Differenzen von vorher-nachher zu berechnen.

Lasse dir dann mit `qqnorm(diff)`und `qqline(diff, col = "red")` das Q-Q-Plot ausgeben.
:::

```{r differenzen, exercise = TRUE, exercise.setup = "fahrradstrasse", exercise.cap = "Differenz berechen" }
df <- df |> 
  mutate(neu = berechnung)
qqnorm(df$diff)
qqline(df$diff, col = "red")
```

```{r differenzen-solution}
df <-  df |> 
  mutate(diff = anzahl_vorher - anzahl_nachher)
qqnorm(df$diff)
qqline(df$diff, col = "red")
```

```{r gepaart}
learnr::question_radio("Wie interpretierst du den Q-Q-Plot bez√ºglich der Normalverteilung der Differenzen?",
      answer("Die Differenzen scheinen normalverteilt zu sein, da die meisten Punkte auf oder nahe der Linie liegen.", 
             correct = TRUE),
      answer("Die Differenzen sind nicht normalverteilt, da die Punkte nicht auf der Linie liegen.",
             message = "Dass die Punkte am Ende der Diagonalen etwas abweichen ist noch vertretbar, aber zur Sicherheit k√∂nntest du hier auch einen Shapiro-Wilk-Test rechnen. "),
      answer("Der QQ-Plot kann nicht verwendet werden, um die Normalverteilung zu √ºberpr√ºfen.",
             message = "Es bedarf zwar etwas √úbung, aber es ist sehr gut m√∂glich, die Normalverteilung anhand des Q-Q-Plots zu untersuchen."),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = "Genau! Dass die Punkte am Ende der Diagonalen etwas abweichen ist noch vertretbar, aber zur Sicherheit k√∂nntest du hier auch einen Shapiro-Wilk-Test rechnen.",
      incorrect= random_encouragement("de"))

```

Zur Sicherheit schauen wir uns also noch das Ergebnis des Shaprio-Wilk Tests f√ºr unsere Differenzen an:

```{r shapiro, exercise = TRUE, exercise.setup = "fahrradstrasse", exercise.cap = "Differenz evaluieren" }
df <-  df |> 
  mutate(diff = anzahl_vorher - anzahl_nachher)
shapiro.test(df$diff)
```

```{r shapirowilkquiz}
learnr::question_radio("Wie interpretierst du den Shapiro-Wilk Test bez√ºglich der Normalverteilung der Differenzen?",
      answer("Sieht gut aus. Sind normalverteilt.", 
             correct = TRUE),
      answer("Wei√ü ich nicht, digga.",
             message = "Kein Problem. Erinnere dich daran, dass die H0 des Tests besagt, dass die Daten normalverteilt sind."),
      answer("Sieht nicht gut aus. Sind nicht normalverteilt.",
             message = "Erinnere dich daran, dass die H0 des Tests besagt, dass die Daten normalverteilt sind. Ein *p*-Wert √ºber 0.05 l√§sst uns schlie√üen, dass wir diese Hypothese beibehalten k√∂nnen."),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = "Genau! Ein *p*-Wert √ºber 0.05 l√§sst uns schlie√üen, dass wir die H0 beibehalten k√∂nnen.",
      incorrect= random_encouragement("de"))

```

### t-Test abh√§ngige Gruppen berechnen

Nach der Pr√ºfung der Voraussetzungen steht unserem *t*-Test jetzt nichts mehr im Wege. Wir m√ºssen der Funktion nur noch mit `paired = TRUE` mitteilen, dass unsere Daten paarweise analysiert werden sollen (abh√§ngig voneinander). Dabei ist wichtig zu beachten, dass unsere Daten den Zeilen nach (in unserem Beispiel pro Tageszeit) analysiert werden, in anderen Beispielen w√ºrden wir pro Person vergleichen (vor und nach einer Intervention).

``` r
t.test(x, y, paired = TRUE)
```

Also los gehts, du bist dran:

::: aufgabe
Finde anhand des t-Tests heraus, ob es einen signifikanten Unterschied an der Anzahl an Radfahrenden durch den Umbau der Stra√üe gegeben hat. Vergleiche daf√ºr `df$anzahl_vorher` mit `df$anzahl_nachher`. Vergiss nicht, dass es ein gepaarter *t*-Test ist und passe auch das Argument f√ºr `alternative` an.
:::

```{r pairedt, exercise = TRUE, exercise.setup = "fahrradstrasse", exercise.cap = "Differenz evaluieren" }
t.test(df$anzahl_vorher, df$anzahl_nachher, 
       paired = TRUE, 
       alternative = "greater")
```

```{r pairedtquiz}
learnr::question_radio("Wie interpretierst du das Ergebnis des gepaarten t-Test f√ºr unsere Studie?",
      answer("Es gibt keinen Unterschied in der Anzahl an Radfahrenden vor und nach dem Umbau.", 
             correct = TRUE),
      answer("Es gibt 44 mehr Radfahrende pro Stunde.",
             message = "Die 44 ist der Freiheitsgrad unseres t-Tests. Sie ist angelehnt and die Anzahl an Beobachtungen."),
      answer("Es gibt 0.038 mehr Radfahrende pro Stunde.",
             message = "Das stimmt zwar, aber unser *p*-Wert sagt uns, dass dies kein signifikanter Anstieg der Anzahl an Radfahrenden ist und daher vernachl√§ssigt werden kann."),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = "Genau! Ein *p*-Wert √ºber 0.05 l√§sst uns schlie√üen, dass wir die H0 beibehalten k√∂nnen. Es gibt also keinen Unterschied in der Anzahl an Radfahrenden vor und nach dem Umbau der Stra√üe.",
      incorrect= random_encouragement("de"))

```

#### Interpretieren und berichten

Auch das ist Teil der Wissenschaft. Nicht alle Effekte die wir vermuten, sind auch tats√§chlich vorhanden. Es ist dennoch sehr wichtig, dass wir auch diese nicht best√§tigten Hypothesen gut berichten:

::: blau-nb
In der Studie wurde ein abh√§ngiger T-Test durchgef√ºhrt, um zu untersuchen, ob sich die Anzahl der Radfahrenden pro Stunde nach dem Umbau einer Stra√üe in eine Fahrradstra√üe signifikant erh√∂ht hat. Die Analyse ergab keinen signifikanten Anstieg in der Anzahl der Radfahrenden ($t(44) = 0.038, p = .485$). Vor dem Umbau betrug die Anzahl der Radfahrenden ($M = 45.08, SD = 8.32$) , nach dem Umbau ($M = 45.01, SD = 7.76$).
:::

Wow! Du hast es geschafft! Jetzt bist du ein t-Test-Profi! Eine letzte Sache m√∂chte ich dir noch mit an die Hand geben, bevor du dich eigenst√§ndig auf den Weg in die Welt der Unterschiede begibst: Die Effektst√§rke.

## Effektst√§rke

Die Effektst√§rke ist ein Ma√ü daf√ºr, **wie gro√ü der Unterschied** oder die Beziehung **zwischen zwei Variablen in einer Studie ist**. W√§hrend der *p*-Wert uns sagt, ob ein Ergebnis im Falle unserer H0 wahrscheinlich ist, gibt uns die Effektst√§rke Aufschluss dar√ºber, wie bedeutend oder wichtig dieses Ergebnis ist.

### Warum ist die Effektst√§rke wichtig?

-   **Erg√§nzung zum *p*-Wert**: Ein statistisch signifikanter P-Wert (z.B. p \< 0.05) bedeutet nicht automatisch, dass ein Effekt praktisch bedeutsam ist. Die Effektst√§rke hilft, die praktische Relevanz eines statistischen Ergebnisses zu bewerten.
-   **Vergleichbarkeit**: Sie erm√∂glicht den Vergleich der St√§rke von Effekten √ºber verschiedene Studien hinweg.
-   **Interpretation**: Effektst√§rken liefern ein tieferes Verst√§ndnis der Daten, das √ºber die blo√üe Signifikanz hinausgeht.

### Berechnung der Effektst√§rke in R

Als Ma√ü f√ºr die Effektst√§rke wird oft Cohens *d* verwendet. 



Cohen (@cohen1988) hat uns auch eine Interpretation dieser Werte in seinem Wissenschaftsbeitrag mitgeliefert:

Interpretation von Cohens $d$:

-   **Kleine** Effektgr√∂√üe: $|d| = 0.2$
-   **Mittlere** Effektgr√∂√üe: $|d| = 0.5$
-   **Gro√üe** Effektgr√∂√üe: $|d| = 0.8$

Berechnen wir also mit der Funktion `cohens_d` aus dem `effectsize`-Paket die Effektgr√∂√üe f√ºr unsere Beispiele:

Die Funktion `cohens_d()` hat die gleiche Funktionsweise wie unser `t.test()`.

```r
cohens_d(
  x,
  y = NULL,
  data = NULL,
  alternative = "two.sided",
  ...
)
```
::: aufgabe
Ermittle die Effektgr√∂√üe f√ºr unseren unabh√§ngigen t-Test, der den Ruhepuls von Autofahrenden und Radfahrenden vergleicht.

Gib der Funktion daf√ºr die Variablen `puls_autofahrende` und `puls_radfahrende`.
:::

```{r cohens, exercise = TRUE, exercise.setup = "ruhepuls", exercise.cap = "Effektst√§rke" }
effectsize::cohens_d()
```

```{r cohens-solution}
effectsize::cohens_d(puls_autofahrende, puls_radfahrende)
```

```{r gepaartquiz}
learnr::question_radio("Wie interpretierst du die Effektst√§rke f√ºr diesen Unterschied nach der Konvention von Cohen?",
      answer("**Mittlere** Effektgr√∂√üe", 
             correct = TRUE),
      answer("**Kleine** Effektgr√∂√üe",
             message = "Alles unter 0.2 wird als kleiner Effekt bezeichnet."),
      answer("**Gro√üe** Effektgr√∂√üe",
             message = "Als gro√üer Effekt gelten nach Cohen erst Effektst√§rken ab 0.8"),
      random_answer_order = TRUE,
      allow_retry = TRUE,
      correct = "Genau! Ein *d* von 0.73 kann als mittlere Effektst√§rke nach Cohen klassifiziert werden.",
      incorrect= random_encouragement("de"))

```

### Berichten der Effektst√§rke

Auch die Effektst√§rke solltest du dann bei deinem Ergebnissteil berichten. Dazu kannst du diese beim Berichten des *t*-Tests mit angeben:

::: blau-nb
"Der unabh√§ngige-*t*-Test ergab einen statistisch signifikanten Unterschied zwischen dem Ruhepuls von Autofahrenden ($M = 79.53, SD = 9.81$) und dem Ruhepuls von Radfahrenden($M = 73.42, SD = 6.68$), $t(51.14) = 2.82, p < .001$ mit einer nach @cohen1988 mittleren Effektst√§rke, $d = 0.72 [0.20, 1.25]$. Dieses Ergebnis deutet darauf hin, dass Autofahrende im durchschnittlich einen h√∂heren Ruhepuls als Radfahrende besitzten."
:::

## Abschlussquiz

```{r Abschlussquiz}
quiz(caption = "Teste dein Wissen!",

  learnr::question_checkbox("Was ist der Unterschied zwischen gerichteten und ungerichteten Hypothesen?",
         answer("Ungerichtete Hypothesen spezifizieren keine Richtung des Unterschieds.", 
                 correct = TRUE,
                 message = "Richtig! Ungerichtete Hypothesen behaupten nur, dass ein Unterschied existiert."),
         answer("Gerichtete Hypothesen werden nur in experimentellen Designs verwendet.",
                 message = "Nicht ganz. Gerichtete Hypothesen k√∂nnen in verschiedenen Studientypen verwendet werden und spezifizieren die erwartete Richtung des Unterschieds."),
         answer("Gerichtete Hypothesen testen Unterschiede in mehr als zwei Gruppen.",
                 message = "Das ist nicht korrekt. Die Anzahl der Gruppen beeinflusst nicht, ob eine Hypothese gerichtet ist oder nicht."),
         allow_retry = TRUE,
         random_answer_order = TRUE
         ),

  learnr::question_radio("Welche Aussage trifft auf den abh√§ngigen *t*-Test zu?",
         answer("Er wird verwendet, um zwei unabh√§ngige Stichproben zu vergleichen.",
              message = "Das ist nicht ganz richtig. Der abh√§ngige *t*-Test vergleicht zwei verbundene oder gepaarte Stichproben."),
         answer("Er vergleicht die Mittelwerte derselben Gruppe zu zwei verschiedenen Zeitpunkten.",
              correct = TRUE,
              message = "Genau! Der abh√§ngige *t*-Test wird f√ºr gepaarte Stichproben verwendet, wie z.B. Messungen an derselben Gruppe zu zwei verschiedenen Zeitpunkten."),
         answer("Er kann ohne Pr√ºfung auf Normalverteilung der Differenzen angewendet werden.",
              message = "Das ist nicht korrekt. Es ist wichtig, die Normalverteilung der Differenzen in den gepaarten Daten zu √ºberpr√ºfen."),
         allow_retry = TRUE,
         random_answer_order = TRUE
         ),

  learnr::question_radio("Wof√ºr wird die Effektst√§rke in einer statistischen Analyse verwendet?",
         answer("Um die Wahrscheinlichkeit eines Typ-1-Fehlers zu bestimmen.",
              message = "Das ist nicht korrekt. Die Effektst√§rke misst die Gr√∂√üe eines Effekts, nicht die Wahrscheinlichkeit eines Fehlers."),
         answer("Um die Gr√∂√üe eines beobachteten Effekts zu quantifizieren.",
              correct = TRUE,
              message = "Richtig! Die Effektst√§rke gibt Aufschluss √ºber die praktische Bedeutung eines statistischen Ergebnisses."),
         answer("Um zu entscheiden, welche statistische Testmethode verwendet werden soll.",
              message = "Das ist nicht ganz richtig. Die Entscheidung f√ºr eine Testmethode basiert auf anderen Kriterien, wie dem Studiendesign und den Verteilungsannahmen."),
         allow_retry = TRUE,
         random_answer_order = TRUE
         ),

  learnr::question_radio("Wie berichtet man die Ergebnisse eines *t*-Tests nach APA-Richtlinien?",
         answer("Indem man nur den *p*-Wert angibt.",
              message = "Das ist nicht ausreichend. Nach APA-Richtlinien sollten auch der *t*-Wert, die Freiheitsgrade und die Mittelwerte mit Standardabweichungen berichtet werden."),
         answer("Indem man den *t*-Wert, die Freiheitsgrade, den *p*-Wert sowie Mittelwerte und Standardabweichungen angibt.",
              correct = TRUE,
              message = "Genau! Ein vollst√§ndiger Bericht nach APA-Richtlinien umfasst all diese statistischen Informationen."),
         answer("Indem man eine ausf√ºhrliche Beschreibung der deskriptiven Analyse gibt.",
              message = "W√§hrend die Beschreibung der deskriptiven Analyse wichtig ist, erfordern APA-Richtlinien spezifische statistische Informationen wie *t*-Wert, Freiheitsgrade und *p*-Wert."),
         allow_retry = TRUE,
         random_answer_order = TRUE
         ))

```

## Learnings

So hast du heute abgeschnitten:

```{r context="server"}
# Shiny App um die Anzahl richtig beantworteter Fragen anzuzeigen. 
# Funktioniert in jedem Tutorial

shiny::observeEvent(
  input$get_score, 
  {
    objs2 = learnr:::get_tutorial_state()
    
    # Number of correct questions
    
    n_correct <- 
      # Access the $correct sublist item in each list item
        lapply(objs2, purrr::pluck, "correct") |>
           # make it a vector containing: TRUE and FALSE and NAs
           # NA is appearing for list items which don't have
           # a $correct subitem
                unlist() |> 
           # Taking the sum of a logical Vector returns the number of TRUEs
                sum(na.rm=TRUE)
    
    # Number of total questions
    
    total_questions <- 
      # 1. Access $type in each list item and make it a vector of types
      lapply(objs2, purrr::pluck, "type") |> unlist()
    
    # 2. Count the number of "question" in that vector
    total_questions <- total_questions[total_questions == "question"] |> 
      length()
      
      
    output$score = shiny::renderText(
      paste0(n_correct, " von ", total_questions,
        " im gesamten Tutorial beantworteten Fragen waren richtig.")
)
    invisible()
  }
)
```

```{r score, echo=FALSE}
shiny::br()
shiny::actionButton("get_score", "Auswertung!")
shiny::br()
shiny::br()
shiny::textOutput("score")
shiny::br()
```

### Zusammenfassung

- Was der *t*-Tests ist und wann er angewendet wird: Der *t*-Tests ist ein statistisches Verfahren, das verwendet wird, um zu testen, ob sich die Mittelwerte zweier Stichproben signifikant voneinander unterscheiden. Es gibt verschiedene Arten von *t*-Tests, einschlie√ülich des Einstichproben-, des unabh√§ngigen und des abh√§ngigen T-Tests.

- Wie man die Voraussetzungen f√ºr den *t*-Tests √ºberpr√ºft: Dazu geh√∂rt die √úberpr√ºfung der Normalverteilung und der Varianzhomogenit√§t.

- Wie man den T-Test in R durchf√ºhrt: Du hast gelernt, wie du den *t*-Tests mit realen und simulierten Daten durchf√ºhrst und wie du die Ergebnisse interpretierst.

- Die Bedeutung von Effektst√§rken: Neben dem P-Wert ist auch die Effektst√§rke wichtig, um die praktische Bedeutung der Ergebnisse zu beurteilen.

- Berichten der Ergebnisse nach APA-Richtlinien: Du hast gesehen, wie man die Ergebnisse eines *t*-Tests pr√§zise und gem√§√ü den APA-Standards berichtet.


### Neue Funktionen

| Funktion in R              | Erkl√§rung                                                  |
|----------------------------|-------------------------------------------------------------|
| `t.test()`                 | Durchf√ºhrung eines T-Tests, einschlie√ülich aller Varianten |
| `qqnorm()`, `qqline()`     | Erstellung von QQ-Plots zur √úberpr√ºfung der **Normalverteilung**|
| `shapiro.test()`           | Durchf√ºhrung des Shapiro-Wilk-Tests zur √úberpr√ºfung der **Normalverteilung** |
| `leveneTest()`             | Durchf√ºhrung des Levene-Tests zur √úberpr√ºfung der **Varianzhomogenit√§t** |
| `mean()`, `sd()`           | Berechnung von Mittelwert und Standardabweichung.           |
| `cohen.d()`                | Berechnung der **Effektst√§rke** (Cohens d) f√ºr T-Tests.         |

## Credit

Dieses Tutorial wurde von Marie Klosterkamp sowie in Teilen von Lukas Bruelheide geschrieben.

## Literaturverzeichnis

<!--  Wird automatisch generiert aus den @autorYYYY-Zitationen und der Bibliothek in ref.json. Das Literaturverzeichnis wird immer ans Ende generiert, deswegen muss das hier die letzte √úberschrift bleiben. -->
