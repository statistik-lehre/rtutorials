---
title: "Wissenschaftlicher Prozess"
output:
  learnr::tutorial:
    language: de
    css: css/boxes.css
    fig_caption: no
runtime: shiny_prerendered
bibliography: ref.json
link-citations: TRUE
description: "Ein grundlegender √úberblick √ºber den wissenschaftlichen Prozess 
als solchen mit optionalem Nachschlagewerk der einzelnen Stationen."
resource_files:
- css/boxes.css
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
library(learnr)
library(haven)
library(car)
library(mice)
library(psych)
knitr::opts_chunk$set(echo = FALSE)

# data
publictr <- rtutorials::publictr

```

## Wissenschaftlicher Prozess

Heute gehen wir einmal *full circle* - den kompletten Wissenschaftlichen Prozess entlag. 
Dabei erh√§lst du einen √úberblick der wichtigesten Funktionen f√ºr jeden Schritt, 
so dass du auch selbstst√§ndig deine Forschung mit *R* bewerkstelligen kannst.
![](images/prozess.png){width="85%"}

Um es einfach zu halten, sind im Flie√ütext nur die groben
Orientierungspunkte, weitere Infos gibt es in den ausklappbaren Men√ºs.

::: gelb
Da wir euch quantitative Verfahren beibringen, bezieht sich die Roadmap
speziell auf quantitative Verfahren. Solltet ihr qualitativ Forschen
wollen, √§ndern sich die Schritte inhaltlich und ggf. auch deren Abfolge
teilweise.
:::

## I) Vorarbeit

Ja, ein Gro√üteil des wissenschaftlichen Arbeitens geschieht vor dem, was
wir uns darunter Vorstellen: Die folgenden Punkte geben dir daf√ºr einen 
kleinen √úberblick:

**1. Einarbeiten**

Jede gute (wissenschaftliche) Arbeit braucht eine gute Vorarbeit: Ein
Einlesen in die Matrie, sich mit dem Feld vertraut und neue Gedanken
machen: was gibt es schon? was braucht es noch? Was kann/ m√∂chte ich
beitragen? Das geschiet meist in Form einer Literaturanalyse.

**2. Fragestellung**

Wenn mensch einen guten √úberblick √ºber das interessierende
Forschungsfeld hat wird im n√§chsten Schritt eine konkrete Fragestellung
entwickelt: *Was m√∂chte ich untersuchen?*

**3. Operationalisierung der Variablen**

Und WIE genau m√∂chte bzw. kann ich das untersuchen?\
Ganz konkret: *Wie kann ich das, was mich interessiert, in Zahlen oder
Kategorien bringen?*

**4. Konkrete, testbare Hypothesen aufstellen**

Du fragst dich: *Welchen Sachverhalt/Effekt m√∂chte ich untersuchen?* Du formulierst 
f√ºr deine Forschungsfrage eine Null(H0)- und Alternativhypothese(H1):

H0: Der Sachverhalt den ich unteruschen m√∂chte existiert nicht
H1: Der Sachverhalt existiert. (eventuell auch bereits die Richtung des Effekts, 
wenn aus der Literatur bekannt)

**(5. Ethikantrag & Datenschutzerkl√§rung)**

Wenn du als Forschungsgegenstand mit Menschen zu tun hast solltest du vorher 
abkl√§ren ob du einen Ethikantrag bei der Ethikkommission deiner Universit√§t oder 
auch eine Datenschutzerkl√§rung mit der Datenschutzbeauftragten Person.  

**(6. Pr√§registrierung)**

Es ist gute wissenschaftliche Praxis deine Studie vor der Durchf√ºhrung auf einem 
*open science portal* wie dem Open Science Framework (OSF) f√ºr eine Pr√§registrierung
anzumelden. Mehr dazu erf√§hrst du [hier](https://www.cos.io/initiatives/prereg).

## II) Messen / Generieren von Daten


**1. Erhebung**

Der Teil, bei dem euch auf dem Campus S√º√üigkeiten f√ºr Studienteilnahmen
angeboten werden (als teilnehmende Person).\
F√ºr die Forschenden Personen ist dieses der Teil, in dem sie Umfragen
durchf√ºhren, Einheiten (bspw. Fahrr√§der am Campus) z√§hlen oder messen,
wie lange eine Person f√ºr eine bestimmten braucht. 


**2. Digitalisieren**

Hast du die Daten analog gesammelt (Umfrage, Z√§hlungen auswerten, etc.), 
m√ºssen diese erstmal in eine f√ºr den Computer lesbare Form gebracht werden: 
Sie werden digitalisiert!\
Es gibt M√∂glichkeiten, sie direkt in *R* zu schreiben, das bringt aber
wenig Spa√ü. Die eleganteste Version ist, sie in Excel oder Open Office
in eine Tabelle zu schreiben und diese dann zu importieren.

<details>

<summary><a>‚ñº \* Hilfreiche Aspekte vor der Digitalisierung
</a></summary>

::: infobox
Damit *R* sp√§ter gut mit den Daten umgehen kann und keine Fehler oder
fehlenden Werte liest, ist es ratsam, auf ein paar zentrale Punkte zu
achten:

1.  **tidy data**: Du sparst dir jede Menge m√ºhe, wenn du die folgenden 
Prinzipien beachtest:

- Jede Spalte ist eine Variable, 
- jede Zeile eine Beobachtungseinheit, 
- jede Zelle ein Wert!

2.  **Datenformatierung**: Stelle sicher, dass die Daten korrekt
    formatiert sind. Dies bedeutet, dass numerische Werte als Zahlen zu
    formatieren (achte auch auf Dezimaltrennzeichen), Datumsangaben als
    Datumswerte usw. Bleibe dabei so grundlegend wie m√∂glich und
    vermeide spezielle Zeichen oder Formatierungen, die zu Problemen
    f√ºhren k√∂nnten.
    
3.  **Spalten√ºberschriften**: Verwende klare, kurze (am besten 1 Wort)
    und aussagekr√§ftige Spalten√ºberschriften. Diese werden als
    *Variable-Namen* verwendet, wenn die Daten in R eingelesen werden.
    Vermeide dabei Sonderzeichen, Leerzeichen und andere Zeichen, die in
    R nicht als g√ºltige Variablennamen verwendet werden k√∂nnen. Wenn du
    die Datei als CSV (s.u.) speichern m√∂chtest (du m√∂chtest sie als CSV
    speichern!), achte darauf, dass die Spalten√ºberschriften in der 1.
    Zeile sind und NUR in der ersten Zeile.¬¥
    
4.  **Leere Zellen und fehlende Werte**: Beachte, wie du leere Zellen
    und fehlende Werte behandeln m√∂chtest. In R werden fehlende Werte
    oft mit "`NA`" repr√§sentiert. Achte darauf, *konsistent* mit
    fehlenden Werten umzugehen, um sp√§tere Analysen nicht zu
    beeintr√§chtigen.
    
5.  **Textkodierung**: Wenn die Daten Text enthalten (z.B. bei
    kategorischen Variablen), achte darauf, die richtige Textkodierung
    zu verwenden. `UTF-8` ist eine g√§ngige Textkodierung, die sowohl in
    *Excel* als auch in *R* unterst√ºtzt wird. 

6.  **Speicherort**: Merke dir den den Speicherort der Datei, in der du
    die Daten gespeichert hast. Du ben√∂tigen diesen Pfad, um die Daten
    in R einzulesen. Noch besser: lege in deinem R-Projekt einen Ordner
    namens "`data`" an. Dort kannst du alle Datens√§tze f√ºr das Projekt
    speichern und dann ist der Pfad zu den daten immer
    `"data\datensatz.csv"`
    
7. **Datumsformate**: Stelle sicher, dass Datumsangaben im richtigen
    Format erfasst werden. In Excel k√∂nnten Datumsangaben je nach Region
    unterschiedlich formatiert sein (z. B. `MM/DD/YYYY` oder
    `DD.MM.YYYY`). 

![](images/venn.jpg){width="25%" style="display:block; margin:auto;"}
:::

</details>

### 2. Datenimport

Als n√§chstes liest du deine Daten in *R* ein. Jetzt kommt es darauf an, in welcher
Form diese Daten vorliegen, dementsprechend brauchen wir verschiedene Funktionen:

1.  CSV: `daten <- read.csv("data/datensatz.csv")`
2. Ecxel: `daten <- openxlsx::read.xlsx("data/datensatz.xlsx)`

Beachte das f√ºr manche Funktionen zuerst das entsprechende Paket (vor dem `::`) 
installiert werden muss (`install.packages("openxlsx")`).

<details>

<summary><a>‚ñº \* Was macht der Code? </a></summary>
::: gelb
-   `data`: Zuerst erstellen wir ein Objekt, dass wir in diesem Fall
    `data` nennen. Bis jetzt ist es wie eine leere Box.
-   `<-`: Dann sagen wir *R*, das es was in die Box tun soll. Das ist eine
    sehr einfache Funktion.
-   `load()`: Auch das ist eine Funktion, es l√§d einen `rda` Datensatz.
-   `"data/publictr.rda"`: Der Datensatz (`"publictr.rda"`) und wo er
    liegt (`"data/"`)

Also nochmal in langsam und zum mitschreiben. Wir sagen zu *R*: Gehe bitte
diesen Weg (`"data/"`) und nimm diesen spezifischen, dort gespeicherten
Datensatz (`"publictr.rda"`) und lade ihn ein (`load()`). Dann speichere
ihn im Arbeitsspeicher (`<-`) unter diesem Namen (`data`).
:::
</details>

</br>

<details>

<summary><a>‚ñº \* Daten √ºber die grafische Oberfl√§che einlesen </a></summary>
::: gelb
1) Steuere wieder das Fenster unten rechts in der R Studio Oberfl√§che an.
![](images/rechts.png){width="100%"}


2) Navigiere dort zum Reiter "Files", falls dieser nicht schon ausgew√§hlt ist.
![](images/files.png){width="100%"}

3) W√§hle dort die Datei in deinem `working directory` aus, die du in R importieren 
m√∂chtest (hier CSV) und klicke auf "Import Dataset".
![](images/selectcsv.png){width="50%"}


![](images/import_dataset.PNG){width="40%"}
4) Ein Fenster √∂ffnet sich in dem du eine Vorschau der Daten siehtst. 
- Unten bei "Import Options" kannst du die Einstellungen √§ndern, 
- Rechts (*blau*) kannst du den Code zum Import mit diesen Einstellungen in die 
Zwischenablage speichern 
- und ganz unten rechts (*rot*) den Import durchf√ºhren.

![](images/grafisch.PNG){width="100%"}

5) Nutze die Zwischenablage, um diesen Code deinem Skript zuzuf√ºgen, damit du 
diese Schritte f√ºr das n√§chste √ñffnen deines Datenasatzes nicht mehr ben√∂tigst.
:::
</details>

Ausf√ºhrliche Anleitungen findest du im Tutorial `3a_import`.

### 3. Datenaufbereitung / Cleaning

Jetzt kommt der Teil, der meistens lange dauert, in der Lehre h√§ufig
√ºbersprungen wird: Die Daten m√ºssen aufbereitet werden. Wer sich hier Zeit l√§sst
und sauber arbeitet, hat sp√§ter keine oder zumindest kaum Probleme bei
der Analyse. Wenn dieser wichtige Schritt abgeschlossen ist, kann der
Spa√ü losgehen.

Um einen Eindruck zu bekommen, wie sowas aussehen kann, kannst du dir
das
[Skript](https://github.com/statistik-lehre/rtutorials/blob/main/data-raw/publictr.R)
ansehen, in dem der `publictr` Datensatz aufger√§umt wird.

Wichtig f√ºr dich **Check your Data**:

*Gibt es Ausrei√üer in deinen Daten?* 
<details>
<summary><a>‚ñº \* Bei Verdacht auf Ausrei√üern: </a></summary>
::: gelb
Gr√ºnde f√ºr Ausrei√üer:

-   Mess- oder ggf. Tippfehler
-   echter Ausrei√üer (Daten geh√∂ren nicht zur Population)

Ein Beispiel: Im Falle eines Fragebogens kann es z.B.
passieren, dass die Probanden eine Frage falsch verstanden haben. Wird
nach dem Geburtsjahr gefragt und du hast einige Antworten die
offensichtilich die Anzahl an Jahren sind (z.B: `61`) handelt es sich um
einen *Mess- bzw. Tippfehler*. Ist die Antwort hingegen `3050` k√∂nnen wir auch
davon ausgehen, dass der *Wert nicht zu unserer Population* geh√∂rt, da dies als 
Geburtsjahr nicht m√∂glich ist. Haben wir als Antwort jedoch den Wert `1920` ist 
dies zwar ein extremer Wert, aber m√∂glich w√§re es durchaus.

Mehr und ausf√ºhrlichere Infos zum Thema Ausrei√üer und Methoden wie du damit
verfahren solltest findest du 
[hier.](https://statistikguru.de/r/ungepaarter-t-test-r/umgang-mit-ausreissern-2.html)

Eine der Methoden (Ausschluss von Ausrei√üern, die weiter als der 1.5fache *IQR* von 50% unserer
Daten entfernt liegt) w√ºrdest du wie folgt umsetzen:

```{r ausreisser1, exercise = TRUE, exercise.cap = "Ausrei√üer beseitigen"}
# zuerst berechnen wir die Grenzwerte Q1 & Q3, sowie die L√§nge der IQR
Q1 <- quantile(einkaufen$weg, .25, na.rm=T)
Q3 <- quantile(einkaufen$weg, .75, na.rm=T)
IQR <- IQR(einkaufen$weg, na.rm=T)

# dann k√∂nnen wir diese benutzen, um ein Subset aus einkaufen zu filtern, bei dem diese Werte ausgeschlossen werden
no_outliers <- einkaufen |> 
  filter(weg > (Q1 - 1.5*IQR) & weg < (Q3 + 1.5*IQR))

# mit `nrow` k√∂nnen wir feststellen, wie viele Zeilen von einkaufen in no_outliers rausgefiltert wurden 
nrow(einkaufen) - nrow(no_outliers)
```
:::
</details>

</br>


*Gibt es Beobachtungen mit vielen NA Eintr√§gen?*
<details>
<summary><a>‚ñº \* Bei gro√üen Mengen an NAs im Datensatz </a></summary>
::: gelb
**NAs ausschlie√üen**

Besonders in Frageb√∂gen kommt es oftmals dazu, dass Personen den
Fragebogen nach einer bestimmten Zeit abbrechen und somit viele `NA`s in unserem 
Datensatz entstehen. Da diese F√§lle f√ºr eine Analyse meist unbrauchbar sind, 
gibt es auch hier eine M√∂glichkeit unseren Datensatz davon zu "reinigen".

```{r narm, exercise = TRUE}
# nur rows mit weniger oder genau 50% NA Werten werden beibehalten
einkaufen[rowMeans(is.na(einkaufen)) <= .5,]
```

Doch auch hier ist Vorsicht geboten. Der Schwellenwert (hier 50%) sollte im 
Vorhinein gut √ºberlegt sein und der **Auschluss der Daten gut dokumentiert 
und berichtet** werden!
:::
</details>
</br>


*Sind deine Daten im richtigen Format vorhanden?* 

Das Paket `dyplr` aus dem `Tidyverse` hat einige n√ºtzliche Funktionen daf√ºr:

-   `rename()` l√§sst dich deine Variablen umbenennen.
-   `select()` erm√∂glicht es dir, Variablen anhand ihrer Namen
    auszuw√§hlen.
-   `filter()`, um F√§lle basierend auf ihren Werten auszuw√§hlen.
-   `summarise()`, fasst mehrere Werte zu einer einzigen Zusammenfassung
    zusammen.
-   `arrange()`, um die Reihenfolge der Zeilen zu √§ndern.
-   `group_by()`, um Funktionen gruppenweise durchzuf√ºhren.

Ausf√ºhrliche Anleitungen findest du im Tutorial `4d_datawrangling`.

## IV) Orientierung in den Daten

Jetzt, wo du deine Daten in *R* eingelesen und aufger√§umt hast,
wollen wir uns einen Eindruck verschaffen: Was haben wir da eigentlich
erhoben?

**1. Numerische Orientierung**

**a) kompletter Datensatz**

::: gelb
N√ºtzliche Befehle, um sich einen √úberblick √ºber den Datensatz zu verschaffen:

    
| Funktion               | Beschreibung                                                                      |
|------------------------|-----------------------------------------------------------------------------------|
| `data`                 | Zeigt den Datensatz in der Konsole. Bietet eine √úbersicht √ºber den gesamten Datensatz, kann jedoch un√ºbersichtlich werden.            |
| `view(data)`           | √ñffnet den kompletten Datensatz als klassische Tabelle in einem neuen Tab im Skript-Fenster. Gut geeignet, um den Datensatz detailliert zu erkunden.  |
| `head(data)`           | Zeigt die ersten paar Zeilen des Datensatzes an. N√ºtzlich, um einen schnellen √úberblick zu erhalten.                                     |
| `car::some(data)`      | Zeigt einige zuf√§llige Zeilen des Datensatzes. Hilfreich, um eine Stichprobe der Daten anzuzeigen.                                        |
| `names(data)`          | Gibt die Variablennamen des Datensatzes zur√ºck.                                                                                            |
| `ncol(data)`           | Gibt die Anzahl der Spalten (Variablen) im Datensatz an.                                                                                     |
| `nrow(data)`           | Gibt die Anzahl der Zeilen (Beobachtungseinheiten) im Datensatz an.                                                                         |
:::

</br>

**b) Einzelne Variablen**

::: gelb
Aber auch inhaltlich interessieren uns die einzelnen
Variablen.

Viele der unten aufgef√ºhrten Funktionen funktionieren nur, wenn keine
Daten fehlen. Wenn du dich bereits mit den fehlenden Werten auseinandergesetzt
hast oder du nur einen ersten Eindruck bekommen wollt, kannst du in vielen
der jeweiligen Funktionen das Argument `na.rm = T` setzen (`na` = NA/ not
available; `rm` = remove; `T` = TRUE/ ja, genau das will ich). Das k√∂nnte
dann so aussehen: `mean(data$variable, na.rm = T)`.


| Funktion                       | Beschreibung                                                                                               |
|--------------------------------|-----------------------------------------------------------------------------------------------------------|
| `sum(is.na(data$variable))`    | Z√§hlt, wie viele fehlende Werte in einer bestimmten Variable vorhanden sind.                                 |
| `sum(is.na(data))`             | Z√§hlt, wie viele fehlende Werte im gesamten Datensatz vorhanden sind.                                        |
| `mean(data$variable)`          | Berechnet den Mittelwert (Durchschnitt) einer bestimmten Variable.                                           |
| `sd(data$variable)`            | Berechnet die Standardabweichung einer Variable.                                                           |
| `range(data$variable)`         | Ermittelt die Spannweite (Differenz zwischen Maximum und Minimum) einer Variable.                           |
| `min(data$variable)`           | Gibt den kleinsten Wert in einer Variable an.                                                               |
| `max(data$variable)`           | Gibt den gr√∂√üten Wert in einer Variable an.                                                                |
| `table(data$variable)`         | Zeigt alle eindeutigen Werte in einer Variable und ihre absolute H√§ufigkeit an. Besonders n√ºtzlich f√ºr nominale oder ordinal skalierte Daten. |
| `psych::describe(data)`        | Wendet viele der oben genannten Funktionen auf den gesamten Datensatz an und bietet eine umfassende √úbersicht.                                           |
| `summary(data)`                | √Ñhnlich wie `describe()`, zeigt jedoch zus√§tzlich fehlende Werte und einige andere Verteilungsparameter wie Schiefe und Kurtosis.                        |
| `class(data$variable)`         | Gibt die Klasse oder den Datentyp einer bestimmten Variable an.                                                |
| `typeof(data$variable)`        | Gibt den internen Datentyp einer Variable an.                                                                |

:::

</br>

**2. Grafische Orientierung**

Die Breitbandverbindung in unser Gehirn sind und bleiben unsere Augen.
Deswegen ist an diesem Punkt des Prozesses eine grafische
Auseinandersetzung mit den Daten zwar nicht notwendig, aber doch sinnvoll. 
Daf√ºr kannst du die simplen Standardfunktionen von R verwenden oder auch ein ggplot
erstellen.

**Base R Funktionen:**

| Code                   | Beschreibung       |
|------------------------|--------------------|
| `bar()`                | Balkendiagramm     |
| `hist()`               | Histogramm         |
| `boxplot()`            | Boxplot            |
| `plot()`               | Punktdiagramm      |
| `plot()`               | Linienplot         |

Beachte `plot()` reagiert dabei spezifisch auf das, was du als Argument eingibst. 
Es ist auch in der Lage Vorannahmen f√ºr dein Modell zu visualisieren, wenn du 
entsprechend das Modell als Input verwendest. Ziemlich beeindruckend.

**GGplot:**

| Code                                         | Beschreibung                                          |
|------------------------|-----------------------------------------------|
| `ggplot()`                                   | Erstellt die Grundebene f√ºr einen Plot                |
| `geom_bar()`                                 | Balkendiagramm                                        |
| `geom_histogram()`                           | Histogramm                                            |
| `geom_boxplot()`                             | Boxplot                                               |
| `geom_point()`                               | Punktdiagramm                                         |
| `geom_line()`                                | Linienplot                                            |
| `aes(x, y, color, fill, shape, size, alpha)` | √Ñsthetisches Mapping von Variablen                    |
| `facet_grid()` und `facet_wrap()`            | Aufteilung von Diagrammen in Raster                   |
| `labs(title, subtitle, x, y, caption)`       | Anpassung von Diagrammtiteln und Achsenbeschriftungen |
| `scale_color_viridis()`                      | Anpassung der Farbskala mit Viridis-Farben            |


### 3. Voraussetzungen pr√ºfen (bisschen langweilig & absolut unerl√§sslich)

Alle Statistiken, die wir sp√§ter berechnen wollen haben spezifische Voraussetzungen, 
die deine Daten erf√ºllen m√ºssen. Diese lassen sich selbstverst√§ndlich auch statistisch testen.

| Funktion                     | Nutzen/Beschreibung |
|------------------------------|---------------------|
| `boxplot(variable1)`         | Erstellt ein Boxplot zur √úberpr√ºfung der Variable auf **Ausrei√üer**.|
| `hist(variable)`             | Erzeugt ein Histogramm, das zur √úberpr√ºfung der **Normalverteilung einer Variable** genutzt wird. |
| `shapiro.test(variable1)`    | F√ºhrt den Shapiro-Wilk-Test zur √úberpr√ºfung der **Normalverteilung der Variablen** durch. |
| `car::leveneTest()`          | Durchf√ºhrung des Levene-Tests zur √úberpr√ºfung der **Varianzhomogenit√§t** |
| `plot(variable1, variable2)` | Erstellt ein Streudiagramm zur √úberpr√ºfung der **Linearit√§t** und der Beziehung zwischen zwei Variablen. |
| `qqnorm(residuen); qqline(residuen, col="red")` | Erstellt einen **Q-Q-Plot** zur √úberpr√ºfung der Normalverteilung von Residuen in einem Regressionsmodell. |
| `plot(model, which = 2)`     | Erzeugt einen **Q-Q-Plot** der Residuen zur √úberpr√ºfung der Normalverteilung in einem Regressionsmodell. |
| `var.test(variable1, variable2)` | F√ºhrt einen F-Test auf Gleichheit der Varianzen durch, n√ºtzlich zur √úberpr√ºfung der **Varianzhomogenit√§t**, beispielsweise vor einem T-Test. |
| `plot(model, which = 1)`     | Zeigt einen Plot der Residuen gegen die gefitteten Werte, n√ºtzlich zur √úberpr√ºfung der **Homoskedastizit√§t.** |
| `lmtest::bptest(model)`      | F√ºhrt den Breusch-Pagan-Test zur √úberpr√ºfung der **Homoskedastizit√§t** der Residuen in einem Regressionsmodell durch. |
| `car::durbinWatsonTest(model)` | Verwendet den Durbin-Watson-Test zur √úberpr√ºfung der **Autokorrelation** der Residuen in einem Regressionsmodell. |
| `shapiro.test(resid(model))` | F√ºhrt den Shapiro-Wilk-Test zur √úberpr√ºfung der **Normalverteilung der Residuen** in einem Regressionsmodell durch. |


## V) Auswertung / Statistik

Hier kommt das Herzst√ºck. Die Analyse, auf die du dich sp√§ter beziehen wirst.

Um einen √úberblick der m√∂glichen statistischen Analysen zu bekommen kannst du dich 
durch diesen Entscheidungsbaum klicken.

@Lukas - wie war nochmal die Internetseite?

F√ºr einen **$t$-Test** sind folgende Funktionen relevant:

+--------------------+-----------------------------------------------------------------+
| Funktion in R      | Beschreibung                                                    |
+====================+=================================================================+
| `t.test()`         | Durchf√ºhrung eines *t*-Tests, einschlie√ülich aller Varianten    |
+--------------------+-----------------------------------------------------------------+

**Korrelation:**

+---------------------------------------------+-----------------------------------------------------------------+
| Funktion in R                               | Beschreibung                                                    |
+=============================================+=================================================================+
| `correlation::correlation()`                | zur Berchenung von Korrelationen                                |
+---------------------------------------------+-----------------------------------------------------------------+
| `GGally::ggscatmat(data, colums = "x","y")` | Erstellt eine Zusammenhangsvisualisierung f√ºr metrische Daten   |
+---------------------------------------------+-----------------------------------------------------------------+

**Regression:**

+---------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+
| Funktion in R                               | Beschreibung                                                                                                                        |
+=============================================+=====================================================================================================================================+
| `lm(outcome ~ predictor, data)`             | Berechnet ein lineares Regressionsmodell.                                                                                           |
| `summary(model)`                            | Gibt eine detaillierte Zusammenfassung des Regressionsmodells aus, einschlie√ülich Koeffizienten, Signifikanzniveaus und Modellg√ºte. |
+---------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------+

Und zur Berechnung der **Effektst√§rke**:

+---------------------------------------------+-----------------------------------------------------------------+
| Funktion in R                               | Beschreibung                                                    |
+=============================================+=================================================================+
| `effectsize::cohens_d()`                    | Berechnung der **Effektst√§rke** (Cohens *d*).                   |
+---------------------------------------------+-----------------------------------------------------------------+

## VI) Sch√∂ne Visualisierungen

Erstelle ansprechende und √ºbersichtliche Grafiken, um deine Ergebnisse zu 
visualisieren, die kommen sp√§ter auch ins Paper.

Siehe hierf√ºr das [ggplot Cheat Sheet](https://rstudio.github.io/cheatsheets/data-visualization.pdf) 
sowie die [R Graph Gallery](https://r-graph-gallery.com/), um deine eigenen 
Plots zu erstellen.üöÄ M√∂chtest du die Grundlagen zuvor erst wiederholen
klicke dich durch das Tutorial `4b_vis`.

## VII) Report

Jetzt will das ganze noch in eine sch√∂ne Form gebracht werden. Hier werden die 
Forschungsergebnisse dokumentiert und ein Bericht je nach Anforderungen 
(Paper, Bachelorarbeit, Studienleistung etc. erstellt). 


## Credit

Dieses Tutorial wurde von Gesa Graf, Lukas Bruelheide sowie Marie Klosterkamp geschrieben. 

